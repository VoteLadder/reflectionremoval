{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd9748-3f4e-422a-a000-de3630fe1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This program will train a model based on the 6_23_ground truth specular dataset creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8785f506-fd03-4564-93f2-bc63e1e37a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:01<00:00, 306MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  33%|███▎      | 101/310 [00:46<01:36,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.3383, AvgP:1.2431, AvgTot:0.4005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  65%|██████▍   | 201/310 [01:34<00:51,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.3072, AvgP:1.1221, AvgTot:0.3633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.2814, AvgP:1.0576, AvgTot:0.3343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 310/310 [02:24<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 Train Total Loss: 0.3319 (L1: 0.2793, P: 1.0526)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 Val Total Loss: 0.2550 (L1: 0.2083, P: 0.9329)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.2550)\n",
      "  Saved val sample to training_samples_perceptual/epoch_1_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.1827, AvgP:0.8809, AvgTot:0.2267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.1630, AvgP:0.8585, AvgTot:0.2059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.1462, AvgP:0.8342, AvgTot:0.1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2 Train Total Loss: 0.1865 (L1: 0.1449, P: 0.8319)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2 Val Total Loss: 0.1377 (L1: 0.0996, P: 0.7614)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.1377)\n",
      "  Saved val sample to training_samples_perceptual/epoch_2_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0882, AvgP:0.7268, AvgTot:0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0790, AvgP:0.7002, AvgTot:0.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0715, AvgP:0.6669, AvgTot:0.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E3 Train Total Loss: 0.1041 (L1: 0.0709, P: 0.6640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation: 100%|██████████| 78/78 [00:15<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E3 Val Total Loss: 0.0841 (L1: 0.0530, P: 0.6229)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0841)\n",
      "  Saved val sample to training_samples_perceptual/epoch_3_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0452, AvgP:0.5311, AvgTot:0.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0412, AvgP:0.5023, AvgTot:0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0383, AvgP:0.4856, AvgTot:0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E4 Train Total Loss: 0.0623 (L1: 0.0380, P: 0.4851)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E4 Val Total Loss: 0.0861 (L1: 0.0477, P: 0.7678)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_4_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0272, AvgP:0.4189, AvgTot:0.0482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0257, AvgP:0.4128, AvgTot:0.0464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0242, AvgP:0.4021, AvgTot:0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E5 Train Total Loss: 0.0441 (L1: 0.0241, P: 0.4008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E5 Val Total Loss: 0.0377 (L1: 0.0198, P: 0.3578)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0377)\n",
      "  Saved val sample to training_samples_perceptual/epoch_5_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0188, AvgP:0.3615, AvgTot:0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0177, AvgP:0.3494, AvgTot:0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0167, AvgP:0.3408, AvgTot:0.0337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E6 Train Total Loss: 0.0336 (L1: 0.0166, P: 0.3400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation: 100%|██████████| 78/78 [00:15<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E6 Val Total Loss: 0.0280 (L1: 0.0126, P: 0.3083)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0280)\n",
      "  Saved val sample to training_samples_perceptual/epoch_6_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0131, AvgP:0.3087, AvgTot:0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0126, AvgP:0.3077, AvgTot:0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0120, AvgP:0.3026, AvgTot:0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E7 Train Total Loss: 0.0272 (L1: 0.0120, P: 0.3039)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E7 Val Total Loss: 0.0261 (L1: 0.0109, P: 0.3051)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0261)\n",
      "  Saved val sample to training_samples_perceptual/epoch_7_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0102, AvgP:0.2940, AvgTot:0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0098, AvgP:0.2885, AvgTot:0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0095, AvgP:0.2856, AvgTot:0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E8 Train Total Loss: 0.0238 (L1: 0.0095, P: 0.2858)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E8 Val Total Loss: 0.0215 (L1: 0.0081, P: 0.2675)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0215)\n",
      "  Saved val sample to training_samples_perceptual/epoch_8_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0084, AvgP:0.2723, AvgTot:0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0080, AvgP:0.2687, AvgTot:0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training:  97%|█████████▋| 301/310 [02:19<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0079, AvgP:0.2676, AvgTot:0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|██████████| 310/310 [02:23<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E9 Train Total Loss: 0.0212 (L1: 0.0078, P: 0.2674)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation: 100%|██████████| 78/78 [00:15<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E9 Val Total Loss: 0.0193 (L1: 0.0065, P: 0.2550)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0193)\n",
      "  Saved val sample to training_samples_perceptual/epoch_9_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0069, AvgP:0.2614, AvgTot:0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0068, AvgP:0.2576, AvgTot:0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0067, AvgP:0.2564, AvgTot:0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E10 Train Total Loss: 0.0196 (L1: 0.0067, P: 0.2567)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E10 Val Total Loss: 0.0179 (L1: 0.0057, P: 0.2446)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0179)\n",
      "  Saved val sample to training_samples_perceptual/epoch_10_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0062, AvgP:0.2545, AvgTot:0.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0062, AvgP:0.2537, AvgTot:0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training:  97%|█████████▋| 301/310 [02:19<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0061, AvgP:0.2519, AvgTot:0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100%|██████████| 310/310 [02:23<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E11 Train Total Loss: 0.0188 (L1: 0.0061, P: 0.2522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E11 Val Total Loss: 0.0172 (L1: 0.0052, P: 0.2393)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0172)\n",
      "  Saved val sample to training_samples_perceptual/epoch_11_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0055, AvgP:0.2399, AvgTot:0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0054, AvgP:0.2403, AvgTot:0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0054, AvgP:0.2430, AvgTot:0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E12 Train Total Loss: 0.0176 (L1: 0.0055, P: 0.2434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E12 Val Total Loss: 0.0167 (L1: 0.0047, P: 0.2406)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0167)\n",
      "  Saved val sample to training_samples_perceptual/epoch_12_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0052, AvgP:0.2411, AvgTot:0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0051, AvgP:0.2403, AvgTot:0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0050, AvgP:0.2388, AvgTot:0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E13 Train Total Loss: 0.0169 (L1: 0.0050, P: 0.2385)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E13 Val Total Loss: 0.0157 (L1: 0.0043, P: 0.2272)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0157)\n",
      "  Saved val sample to training_samples_perceptual/epoch_13_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0049, AvgP:0.2378, AvgTot:0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0048, AvgP:0.2362, AvgTot:0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0048, AvgP:0.2345, AvgTot:0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E14 Train Total Loss: 0.0165 (L1: 0.0048, P: 0.2347)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E14 Val Total Loss: 0.0151 (L1: 0.0039, P: 0.2242)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0151)\n",
      "  Saved val sample to training_samples_perceptual/epoch_14_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0046, AvgP:0.2338, AvgTot:0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0044, AvgP:0.2312, AvgTot:0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0044, AvgP:0.2304, AvgTot:0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E15 Train Total Loss: 0.0159 (L1: 0.0044, P: 0.2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E15 Val Total Loss: 0.0157 (L1: 0.0044, P: 0.2270)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_15_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0043, AvgP:0.2300, AvgTot:0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0042, AvgP:0.2273, AvgTot:0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0042, AvgP:0.2267, AvgTot:0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E16 Train Total Loss: 0.0155 (L1: 0.0042, P: 0.2260)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E16 Val Total Loss: 0.0142 (L1: 0.0033, P: 0.2173)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0142)\n",
      "  Saved val sample to training_samples_perceptual/epoch_16_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0039, AvgP:0.2210, AvgTot:0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0040, AvgP:0.2231, AvgTot:0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0040, AvgP:0.2245, AvgTot:0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E17 Train Total Loss: 0.0153 (L1: 0.0040, P: 0.2245)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E17 Val Total Loss: 0.0138 (L1: 0.0031, P: 0.2139)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0138)\n",
      "  Saved val sample to training_samples_perceptual/epoch_17_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0040, AvgP:0.2259, AvgTot:0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0038, AvgP:0.2209, AvgTot:0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0038, AvgP:0.2199, AvgTot:0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E18 Train Total Loss: 0.0148 (L1: 0.0038, P: 0.2198)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E18 Val Total Loss: 0.0144 (L1: 0.0037, P: 0.2128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_18_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0039, AvgP:0.2230, AvgTot:0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0038, AvgP:0.2210, AvgTot:0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0039, AvgP:0.2215, AvgTot:0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E19 Train Total Loss: 0.0149 (L1: 0.0039, P: 0.2210)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E19 Val Total Loss: 0.0138 (L1: 0.0029, P: 0.2173)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_19_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0035, AvgP:0.2158, AvgTot:0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0036, AvgP:0.2166, AvgTot:0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training:  97%|█████████▋| 301/310 [02:19<00:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0036, AvgP:0.2157, AvgTot:0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training: 100%|██████████| 310/310 [02:23<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E20 Train Total Loss: 0.0144 (L1: 0.0036, P: 0.2161)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E20 Val Total Loss: 0.0132 (L1: 0.0028, P: 0.2075)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0132)\n",
      "  Saved val sample to training_samples_perceptual/epoch_20_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0038, AvgP:0.2184, AvgTot:0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0036, AvgP:0.2162, AvgTot:0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training:  97%|█████████▋| 301/310 [02:19<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0036, AvgP:0.2143, AvgTot:0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training: 100%|██████████| 310/310 [02:23<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E21 Train Total Loss: 0.0143 (L1: 0.0036, P: 0.2142)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E21 Val Total Loss: 0.0131 (L1: 0.0028, P: 0.2062)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0131)\n",
      "  Saved val sample to training_samples_perceptual/epoch_21_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0034, AvgP:0.2125, AvgTot:0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0033, AvgP:0.2093, AvgTot:0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training:  97%|█████████▋| 301/310 [02:19<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0034, AvgP:0.2118, AvgTot:0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training: 100%|██████████| 310/310 [02:23<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E22 Train Total Loss: 0.0139 (L1: 0.0034, P: 0.2115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E22 Val Total Loss: 0.0130 (L1: 0.0027, P: 0.2048)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0130)\n",
      "  Saved val sample to training_samples_perceptual/epoch_22_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0034, AvgP:0.2114, AvgTot:0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0034, AvgP:0.2116, AvgTot:0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0034, AvgP:0.2106, AvgTot:0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E23 Train Total Loss: 0.0139 (L1: 0.0034, P: 0.2106)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E23 Val Total Loss: 0.0128 (L1: 0.0027, P: 0.2031)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0128)\n",
      "  Saved val sample to training_samples_perceptual/epoch_23_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0031, AvgP:0.2057, AvgTot:0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0033, AvgP:0.2088, AvgTot:0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0033, AvgP:0.2093, AvgTot:0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E24 Train Total Loss: 0.0138 (L1: 0.0033, P: 0.2091)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E24 Val Total Loss: 0.0128 (L1: 0.0028, P: 0.2012)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_24_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0030, AvgP:0.2064, AvgTot:0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0031, AvgP:0.2047, AvgTot:0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0032, AvgP:0.2065, AvgTot:0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E25 Train Total Loss: 0.0135 (L1: 0.0032, P: 0.2065)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E25 Val Total Loss: 0.0127 (L1: 0.0027, P: 0.2003)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0127)\n",
      "  Saved val sample to training_samples_perceptual/epoch_25_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0031, AvgP:0.2050, AvgTot:0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0031, AvgP:0.2038, AvgTot:0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0031, AvgP:0.2050, AvgTot:0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E26 Train Total Loss: 0.0134 (L1: 0.0031, P: 0.2053)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E26 Val Total Loss: 0.0123 (L1: 0.0024, P: 0.1972)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0123)\n",
      "  Saved val sample to training_samples_perceptual/epoch_26_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0033, AvgP:0.2114, AvgTot:0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0032, AvgP:0.2067, AvgTot:0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training:  97%|█████████▋| 301/310 [02:19<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0031, AvgP:0.2032, AvgTot:0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E27 Train Total Loss: 0.0133 (L1: 0.0031, P: 0.2035)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E27 Val Total Loss: 0.0125 (L1: 0.0026, P: 0.1994)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_27_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0032, AvgP:0.2088, AvgTot:0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0031, AvgP:0.2033, AvgTot:0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0031, AvgP:0.2039, AvgTot:0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E28 Train Total Loss: 0.0133 (L1: 0.0031, P: 0.2036)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E28 Val Total Loss: 0.0124 (L1: 0.0024, P: 0.1990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_28_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0032, AvgP:0.2102, AvgTot:0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0032, AvgP:0.2058, AvgTot:0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0031, AvgP:0.2030, AvgTot:0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E29 Train Total Loss: 0.0132 (L1: 0.0031, P: 0.2031)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E29 Val Total Loss: 0.0126 (L1: 0.0028, P: 0.1964)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_29_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0030, AvgP:0.2006, AvgTot:0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0030, AvgP:0.2007, AvgTot:0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0030, AvgP:0.2008, AvgTot:0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E30 Train Total Loss: 0.0130 (L1: 0.0030, P: 0.1999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E30 Val Total Loss: 0.0120 (L1: 0.0023, P: 0.1931)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0120)\n",
      "  Saved val sample to training_samples_perceptual/epoch_30_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0029, AvgP:0.1950, AvgTot:0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0029, AvgP:0.1963, AvgTot:0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0030, AvgP:0.1983, AvgTot:0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E31 Train Total Loss: 0.0129 (L1: 0.0030, P: 0.1985)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E31 Val Total Loss: 0.0124 (L1: 0.0027, P: 0.1941)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_31_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0030, AvgP:0.2004, AvgTot:0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0030, AvgP:0.2003, AvgTot:0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0029, AvgP:0.1976, AvgTot:0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E32 Train Total Loss: 0.0128 (L1: 0.0029, P: 0.1981)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E32 Val Total Loss: 0.0122 (L1: 0.0026, P: 0.1934)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_32_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0029, AvgP:0.1974, AvgTot:0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0030, AvgP:0.1963, AvgTot:0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0030, AvgP:0.1976, AvgTot:0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E33 Train Total Loss: 0.0128 (L1: 0.0030, P: 0.1971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E33 Val Total Loss: 0.0117 (L1: 0.0023, P: 0.1885)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0117)\n",
      "  Saved val sample to training_samples_perceptual/epoch_33_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0027, AvgP:0.1923, AvgTot:0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0029, AvgP:0.1955, AvgTot:0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0028, AvgP:0.1945, AvgTot:0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E34 Train Total Loss: 0.0125 (L1: 0.0028, P: 0.1943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E34 Val Total Loss: 0.0120 (L1: 0.0023, P: 0.1930)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_34_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0029, AvgP:0.1975, AvgTot:0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0029, AvgP:0.1969, AvgTot:0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0029, AvgP:0.1981, AvgTot:0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E35 Train Total Loss: 0.0128 (L1: 0.0029, P: 0.1981)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E35 Val Total Loss: 0.0117 (L1: 0.0023, P: 0.1886)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_35_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0030, AvgP:0.1932, AvgTot:0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0030, AvgP:0.1945, AvgTot:0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0029, AvgP:0.1936, AvgTot:0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E36 Train Total Loss: 0.0126 (L1: 0.0029, P: 0.1938)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E36 Val Total Loss: 0.0116 (L1: 0.0022, P: 0.1878)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0116)\n",
      "  Saved val sample to training_samples_perceptual/epoch_36_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0027, AvgP:0.1921, AvgTot:0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0027, AvgP:0.1913, AvgTot:0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0027, AvgP:0.1906, AvgTot:0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E37 Train Total Loss: 0.0123 (L1: 0.0027, P: 0.1911)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E37 Val Total Loss: 0.0118 (L1: 0.0024, P: 0.1892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_37_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0027, AvgP:0.1917, AvgTot:0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0026, AvgP:0.1882, AvgTot:0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0027, AvgP:0.1903, AvgTot:0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E38 Train Total Loss: 0.0122 (L1: 0.0027, P: 0.1905)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E38 Val Total Loss: 0.0117 (L1: 0.0024, P: 0.1878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_38_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0028, AvgP:0.1936, AvgTot:0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0027, AvgP:0.1921, AvgTot:0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0027, AvgP:0.1896, AvgTot:0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E39 Train Total Loss: 0.0122 (L1: 0.0027, P: 0.1897)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E39 Val Total Loss: 0.0114 (L1: 0.0022, P: 0.1842)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0114)\n",
      "  Saved val sample to training_samples_perceptual/epoch_39_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0027, AvgP:0.1876, AvgTot:0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0027, AvgP:0.1891, AvgTot:0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0027, AvgP:0.1889, AvgTot:0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E40 Train Total Loss: 0.0122 (L1: 0.0027, P: 0.1889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E40 Val Total Loss: 0.0114 (L1: 0.0022, P: 0.1841)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_40_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0026, AvgP:0.1859, AvgTot:0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0027, AvgP:0.1868, AvgTot:0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0027, AvgP:0.1877, AvgTot:0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E41 Train Total Loss: 0.0120 (L1: 0.0027, P: 0.1876)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E41 Val Total Loss: 0.0118 (L1: 0.0027, P: 0.1834)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_41_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0027, AvgP:0.1882, AvgTot:0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0026, AvgP:0.1857, AvgTot:0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0026, AvgP:0.1868, AvgTot:0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E42 Train Total Loss: 0.0120 (L1: 0.0026, P: 0.1866)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E42 Val Total Loss: 0.0111 (L1: 0.0021, P: 0.1801)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0111)\n",
      "  Saved val sample to training_samples_perceptual/epoch_42_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0025, AvgP:0.1820, AvgTot:0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0026, AvgP:0.1848, AvgTot:0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0025, AvgP:0.1841, AvgTot:0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E43 Train Total Loss: 0.0117 (L1: 0.0025, P: 0.1842)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Validation: 100%|██████████| 78/78 [00:15<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E43 Val Total Loss: 0.0113 (L1: 0.0022, P: 0.1808)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_43_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0026, AvgP:0.1839, AvgTot:0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0026, AvgP:0.1842, AvgTot:0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0026, AvgP:0.1841, AvgTot:0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E44 Train Total Loss: 0.0118 (L1: 0.0026, P: 0.1841)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Validation: 100%|██████████| 78/78 [00:15<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E44 Val Total Loss: 0.0113 (L1: 0.0022, P: 0.1832)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_44_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0026, AvgP:0.1844, AvgTot:0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0025, AvgP:0.1822, AvgTot:0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0026, AvgP:0.1834, AvgTot:0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E45 Train Total Loss: 0.0117 (L1: 0.0026, P: 0.1834)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E45 Val Total Loss: 0.0116 (L1: 0.0024, P: 0.1831)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_45_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0026, AvgP:0.1856, AvgTot:0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0026, AvgP:0.1840, AvgTot:0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0025, AvgP:0.1819, AvgTot:0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E46 Train Total Loss: 0.0116 (L1: 0.0025, P: 0.1821)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E46 Val Total Loss: 0.0111 (L1: 0.0021, P: 0.1790)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0111)\n",
      "  Saved val sample to training_samples_perceptual/epoch_46_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0025, AvgP:0.1817, AvgTot:0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0025, AvgP:0.1809, AvgTot:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0025, AvgP:0.1804, AvgTot:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E47 Train Total Loss: 0.0115 (L1: 0.0025, P: 0.1806)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E47 Val Total Loss: 0.0111 (L1: 0.0021, P: 0.1803)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_47_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0025, AvgP:0.1828, AvgTot:0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0025, AvgP:0.1832, AvgTot:0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0025, AvgP:0.1809, AvgTot:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E48 Train Total Loss: 0.0115 (L1: 0.0025, P: 0.1805)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E48 Val Total Loss: 0.0111 (L1: 0.0021, P: 0.1808)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_48_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0025, AvgP:0.1791, AvgTot:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Training:  65%|██████▍   | 201/310 [01:33<00:51,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0026, AvgP:0.1830, AvgTot:0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0025, AvgP:0.1801, AvgTot:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E49 Train Total Loss: 0.0115 (L1: 0.0025, P: 0.1801)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Validation: 100%|██████████| 78/78 [00:15<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E49 Val Total Loss: 0.0112 (L1: 0.0023, P: 0.1766)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_49_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0023, AvgP:0.1759, AvgTot:0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0024, AvgP:0.1775, AvgTot:0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0024, AvgP:0.1789, AvgTot:0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E50 Train Total Loss: 0.0114 (L1: 0.0024, P: 0.1791)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Validation: 100%|██████████| 78/78 [00:15<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E50 Val Total Loss: 0.0112 (L1: 0.0022, P: 0.1799)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_50_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0024, AvgP:0.1760, AvgTot:0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0024, AvgP:0.1778, AvgTot:0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0024, AvgP:0.1777, AvgTot:0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E51 Train Total Loss: 0.0113 (L1: 0.0024, P: 0.1779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E51 Val Total Loss: 0.0110 (L1: 0.0022, P: 0.1753)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0110)\n",
      "  Saved val sample to training_samples_perceptual/epoch_51_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0024, AvgP:0.1759, AvgTot:0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0025, AvgP:0.1773, AvgTot:0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0025, AvgP:0.1777, AvgTot:0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E52 Train Total Loss: 0.0114 (L1: 0.0025, P: 0.1779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E52 Val Total Loss: 0.0110 (L1: 0.0022, P: 0.1760)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_52_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0025, AvgP:0.1822, AvgTot:0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0024, AvgP:0.1762, AvgTot:0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0024, AvgP:0.1770, AvgTot:0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E53 Train Total Loss: 0.0113 (L1: 0.0024, P: 0.1770)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E53 Val Total Loss: 0.0112 (L1: 0.0024, P: 0.1757)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_53_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0024, AvgP:0.1754, AvgTot:0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0024, AvgP:0.1729, AvgTot:0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0025, AvgP:0.1764, AvgTot:0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E54 Train Total Loss: 0.0113 (L1: 0.0025, P: 0.1764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E54 Val Total Loss: 0.0110 (L1: 0.0021, P: 0.1784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_54_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0024, AvgP:0.1750, AvgTot:0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0024, AvgP:0.1761, AvgTot:0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0024, AvgP:0.1751, AvgTot:0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E55 Train Total Loss: 0.0111 (L1: 0.0024, P: 0.1750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Validation: 100%|██████████| 78/78 [00:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E55 Val Total Loss: 0.0110 (L1: 0.0022, P: 0.1761)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_55_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0025, AvgP:0.1756, AvgTot:0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0024, AvgP:0.1747, AvgTot:0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0024, AvgP:0.1741, AvgTot:0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E56 Train Total Loss: 0.0111 (L1: 0.0024, P: 0.1742)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 Validation: 100%|██████████| 78/78 [00:15<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E56 Val Total Loss: 0.0106 (L1: 0.0020, P: 0.1724)\n",
      "  Saved best model to specular_removal_unet_perceptual_emphasis.pth (Val Total Loss: 0.0106)\n",
      "  Saved val sample to training_samples_perceptual/epoch_56_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0025, AvgP:0.1805, AvgTot:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0024, AvgP:0.1738, AvgTot:0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 Training:  97%|█████████▋| 301/310 [02:20<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B300/310 - AvgL1:0.0024, AvgP:0.1733, AvgTot:0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 Training: 100%|██████████| 310/310 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E57 Train Total Loss: 0.0111 (L1: 0.0024, P: 0.1738)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 Validation: 100%|██████████| 78/78 [00:15<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E57 Val Total Loss: 0.0106 (L1: 0.0020, P: 0.1726)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved val sample to training_samples_perceptual/epoch_57_sample.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 Training:  33%|███▎      | 101/310 [00:47<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B100/310 - AvgL1:0.0022, AvgP:0.1731, AvgTot:0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 Training:  65%|██████▍   | 201/310 [01:33<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  B200/310 - AvgL1:0.0023, AvgP:0.1712, AvgTot:0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 Training:  92%|█████████▏| 286/310 [02:13<00:11,  2.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 253\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Dataset dirs not set up or empty. Run ground truth generation script first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 194\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m total_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    193\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 194\u001b[0m epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m epoch_l1_loss_val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_l1\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    196\u001b[0m epoch_perceptual_loss_val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_perceptual\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision # Import torchvision to check version\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration (Keep as is) ---\n",
    "DATASET_CONFIG = {\n",
    "    \"ORIGINAL_DIR\": \"dataset/original_frames\",\n",
    "    \"GROUND_TRUTH_DIR\": \"dataset/ground_truth_frames\",\n",
    "    \"TARGET_IMG_SIZE\": (512, 512),\n",
    "    \"BATCH_SIZE\": 4,\n",
    "    \"NUM_EPOCHS\": 100,\n",
    "    \"LEARNING_RATE\": 1e-4,\n",
    "    \"MODEL_SAVE_PATH\": \"specular_removal_unet_perceptual_emphasis.pth\",\n",
    "    \"VGG_FEATURE_LAYERS\": [3, 8, 17, 26],\n",
    "    \"PERCEPTUAL_LOSS_WEIGHT\": 0.05\n",
    "}\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "# --- U-Net Components (Unchanged - as in previous correct version) ---\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels: mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(nn.MaxPool2d(2), DoubleConv(in_channels, out_channels))\n",
    "    def forward(self, x): return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY, diffX = x2.size()[2] - x1.size()[2], x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x): return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels_in, n_channels_out, bilinear=True, base_features=64):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = DoubleConv(n_channels_in, base_features)\n",
    "        self.down1 = Down(base_features, base_features * 2)\n",
    "        self.down2 = Down(base_features * 2, base_features * 4)\n",
    "        self.down3 = Down(base_features * 4, base_features * 8)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(base_features * 8, base_features * 16 // factor)\n",
    "        self.up1 = Up(base_features * 16, base_features * 8 // factor, bilinear)\n",
    "        self.up2 = Up(base_features * 8, base_features * 4 // factor, bilinear)\n",
    "        self.up3 = Up(base_features * 4, base_features * 2 // factor, bilinear)\n",
    "        self.up4 = Up(base_features * 2, base_features, bilinear)\n",
    "        self.outc = OutConv(base_features, n_channels_out)\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x); x2 = self.down1(x1); x3 = self.down2(x2); x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4); x = self.up2(x, x3); x = self.up3(x, x2); x = self.up4(x, x1)\n",
    "        return torch.sigmoid(self.outc(x))\n",
    "\n",
    "# --- Perceptual Loss (Corrected VGG loading) ---\n",
    "class VGGPerceptualLoss(nn.Module):\n",
    "    def __init__(self, feature_layers=None, use_input_norm=True, requires_grad=False):\n",
    "        super(VGGPerceptualLoss, self).__init__()\n",
    "\n",
    "        try:\n",
    "            self.vgg_features = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features.to(DEVICE).eval()\n",
    "            # print(\"Using torchvision VGG19 with 'weights' parameter.\")\n",
    "        except TypeError:\n",
    "            # Fallback to `pretrained=True` for older torchvision versions\n",
    "            self.vgg_features = models.vgg19(pretrained=True).features.to(DEVICE).eval()\n",
    "            # print(\"Using torchvision VGG19 with 'pretrained=True' parameter (older torchvision).\")\n",
    "\n",
    "        if use_input_norm:\n",
    "            self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                  std=[0.229, 0.224, 0.225])\n",
    "        else:\n",
    "            self.normalize = nn.Identity()\n",
    "\n",
    "        if feature_layers is None:\n",
    "            self.feature_layers_idx = [3, 8, 17, 26, 35] \n",
    "        else:\n",
    "            self.feature_layers_idx = feature_layers\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in self.vgg_features.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.loss_fn = nn.L1Loss()\n",
    "\n",
    "    def get_features(self, x):\n",
    "        x = self.normalize(x)\n",
    "        features = []\n",
    "        current_max_idx = max(self.feature_layers_idx) # Get max index once\n",
    "        for i, layer in enumerate(self.vgg_features):\n",
    "            x = layer(x)\n",
    "            if i in self.feature_layers_idx:\n",
    "                features.append(x)\n",
    "            if i >= current_max_idx: # Optimization: stop if past last needed layer\n",
    "                break\n",
    "        return features\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred_features = self.get_features(pred)\n",
    "        target_features = self.get_features(target)\n",
    "        loss = 0\n",
    "        for pf, tf in zip(pred_features, target_features):\n",
    "            loss += self.loss_fn(pf, tf)\n",
    "        return loss\n",
    "\n",
    "# --- Dataset and DataLoader (Unchanged) ---\n",
    "class SpecularRemovalDataset(Dataset):\n",
    "    def __init__(self, original_dir, gt_dir, img_size):\n",
    "        self.original_dir = original_dir\n",
    "        self.gt_dir = gt_dir\n",
    "        self.img_size = img_size\n",
    "        self.original_files = sorted([f for f in os.listdir(original_dir) if f.endswith('.png')])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(img_size),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    def __len__(self): return len(self.original_files)\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.original_files[idx]\n",
    "        original_img = Image.open(os.path.join(self.original_dir, fname)).convert(\"RGB\")\n",
    "        gt_img = Image.open(os.path.join(self.gt_dir, fname)).convert(\"RGB\")\n",
    "        return self.transform(original_img), self.transform(gt_img)\n",
    "\n",
    "# --- Training Loop (Unchanged - as in previous correct version) ---\n",
    "def train_model():\n",
    "    dataset = SpecularRemovalDataset(\n",
    "        DATASET_CONFIG[\"ORIGINAL_DIR\"], DATASET_CONFIG[\"GROUND_TRUTH_DIR\"], DATASET_CONFIG[\"TARGET_IMG_SIZE\"]\n",
    "    )\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    num_workers = min(4, os.cpu_count() // 2 if os.cpu_count() and os.cpu_count() > 1 else 1)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=DATASET_CONFIG[\"BATCH_SIZE\"], shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=DATASET_CONFIG[\"BATCH_SIZE\"], shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    model = UNet(n_channels_in=3, n_channels_out=3, base_features=64).to(DEVICE)\n",
    "    l1_loss_fn = nn.L1Loss().to(DEVICE)\n",
    "    perceptual_loss_fn = VGGPerceptualLoss(feature_layers=DATASET_CONFIG[\"VGG_FEATURE_LAYERS\"]).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=DATASET_CONFIG[\"LEARNING_RATE\"])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(DATASET_CONFIG[\"NUM_EPOCHS\"]):\n",
    "        model.train()\n",
    "        epoch_train_loss, epoch_l1_loss_val, epoch_perceptual_loss_val = 0.0, 0.0, 0.0\n",
    "        \n",
    "        for batch_idx, (originals, gts) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")):\n",
    "            originals, gts = originals.to(DEVICE), gts.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(originals)\n",
    "            loss_l1 = l1_loss_fn(predictions, gts)\n",
    "            loss_perceptual = perceptual_loss_fn(predictions, gts)\n",
    "            total_loss = loss_l1 + DATASET_CONFIG[\"PERCEPTUAL_LOSS_WEIGHT\"] * loss_perceptual\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += total_loss.item()\n",
    "            epoch_l1_loss_val += loss_l1.item()\n",
    "            epoch_perceptual_loss_val += loss_perceptual.item()\n",
    "\n",
    "            if batch_idx > 0 and batch_idx % 100 == 0:\n",
    "                 tqdm.write(f\"  B{batch_idx}/{len(train_loader)} - AvgL1:{epoch_l1_loss_val/(batch_idx+1):.4f}, AvgP:{epoch_perceptual_loss_val/(batch_idx+1):.4f}, AvgTot:{epoch_train_loss/(batch_idx+1):.4f}\")\n",
    "\n",
    "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "        avg_l1_train = epoch_l1_loss_val / len(train_loader)\n",
    "        avg_perceptual_train = epoch_perceptual_loss_val / len(train_loader)\n",
    "        print(f\"E{epoch+1} Train Total Loss: {avg_train_loss:.4f} (L1: {avg_l1_train:.4f}, P: {avg_perceptual_train:.4f})\")\n",
    "\n",
    "        model.eval()\n",
    "        epoch_val_loss, epoch_val_l1_loss, epoch_val_perceptual_loss = 0.0, 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for originals_val, gts_val in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "                originals_val, gts_val = originals_val.to(DEVICE), gts_val.to(DEVICE)\n",
    "                predictions_val = model(originals_val)\n",
    "                val_loss_l1 = l1_loss_fn(predictions_val, gts_val)\n",
    "                val_loss_perceptual = perceptual_loss_fn(predictions_val, gts_val)\n",
    "                total_val_loss_batch = val_loss_l1 + DATASET_CONFIG[\"PERCEPTUAL_LOSS_WEIGHT\"] * val_loss_perceptual\n",
    "                epoch_val_loss += total_val_loss_batch.item()\n",
    "                epoch_val_l1_loss += val_loss_l1.item()\n",
    "                epoch_val_perceptual_loss += val_loss_perceptual.item()\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        avg_val_l1 = epoch_val_l1_loss / len(val_loader)\n",
    "        avg_val_perceptual = epoch_val_perceptual_loss / len(val_loader)\n",
    "        print(f\"E{epoch+1} Val Total Loss: {avg_val_loss:.4f} (L1: {avg_val_l1:.4f}, P: {avg_val_perceptual:.4f})\")\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), DATASET_CONFIG[\"MODEL_SAVE_PATH\"])\n",
    "            print(f\"  Saved best model to {DATASET_CONFIG['MODEL_SAVE_PATH']} (Val Total Loss: {best_val_loss:.4f})\")\n",
    "        \n",
    "        if val_loader and (epoch + 1) % 1 == 0 :\n",
    "            try:\n",
    "                originals_sample, gts_sample = next(iter(val_loader))\n",
    "                originals_sample, gts_sample = originals_sample.to(DEVICE)[:1], gts_sample.to(DEVICE)[:1]\n",
    "                with torch.no_grad(): prediction_sample = model(originals_sample)\n",
    "                orig_np = (originals_sample[0].cpu().permute(1,2,0).numpy()*255).clip(0,255).astype(np.uint8)\n",
    "                gt_np = (gts_sample[0].cpu().permute(1,2,0).numpy()*255).clip(0,255).astype(np.uint8)\n",
    "                pred_np = (prediction_sample[0].cpu().permute(1,2,0).numpy()*255).clip(0,255).astype(np.uint8)\n",
    "                comparison_img = np.concatenate((cv2.cvtColor(orig_np,cv2.COLOR_RGB2BGR), cv2.cvtColor(pred_np,cv2.COLOR_RGB2BGR), cv2.cvtColor(gt_np,cv2.COLOR_RGB2BGR)), axis=1)\n",
    "                sample_save_dir = \"training_samples_perceptual\"\n",
    "                os.makedirs(sample_save_dir, exist_ok=True)\n",
    "                cv2.imwrite(os.path.join(sample_save_dir, f\"epoch_{epoch+1}_sample.png\"), comparison_img)\n",
    "                print(f\"  Saved val sample to {sample_save_dir}/epoch_{epoch+1}_sample.png\")\n",
    "            except StopIteration: print(\"  Val loader empty, cannot save sample.\")\n",
    "\n",
    "    print(f\"Training finished. Best model saved to {DATASET_CONFIG['MODEL_SAVE_PATH']} (Val Total Loss: {best_val_loss:.4f})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(DATASET_CONFIG[\"ORIGINAL_DIR\"]) or \\\n",
    "       not os.path.exists(DATASET_CONFIG[\"GROUND_TRUTH_DIR\"]) or \\\n",
    "       not os.listdir(DATASET_CONFIG[\"ORIGINAL_DIR\"]):\n",
    "        print(\"Error: Dataset dirs not set up or empty. Run ground truth generation script first.\")\n",
    "    else:\n",
    "        train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a79157-6334-4b5a-ba27-065d7a219660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e826ac6-ec80-4880-8099-f84b0c7aeab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
