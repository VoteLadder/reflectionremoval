{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791eb1f1-915d-48c3-8d7c-61c21d49f12f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_wavelets\n",
      "  Downloading pytorch_wavelets-1.3.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch_wavelets) (1.26.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from pytorch_wavelets) (1.16.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch_wavelets) (2.1.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_wavelets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_wavelets) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_wavelets) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_wavelets) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_wavelets) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_wavelets) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_wavelets) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch_wavelets) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->pytorch_wavelets) (1.3.0)\n",
      "Downloading pytorch_wavelets-1.3.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytorch_wavelets\n",
      "Successfully installed pytorch_wavelets-1.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0d7344-9ba1-4d4a-ae34-1ebab7ffcc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "Clear image directory : /notebooks/output_3_18/smokeV2/clear\n",
      "Blurry image directory: /notebooks/output_3_18/smokeV2/blurry\n",
      "Output directory      : /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED\n",
      "---------------------\n",
      "Using device: cuda\n",
      "Total paired samples available for this dataset instance: 7418\n",
      "Total samples: 7418\n",
      "Train/Val split: 5934/1484 (80.0% / 20.0%)\n",
      "Using 1000 train samples per epoch (requested: 1000)\n",
      "Using 200 val samples per epoch (requested: 200)\n",
      "Using specified num_workers: 4\n",
      "\n",
      "--- Starting Training for 50 epochs ---\n",
      "\n",
      "Epoch 1/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Avg Loss: 0.069688\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation Avg Loss: 0.026880\n",
      "*** New best model saved with Validation Loss 0.026880 at Epoch 1 ***\n",
      "Epoch 1 completed in 0:02:19\n",
      "\n",
      "Epoch 2/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training Avg Loss: 0.024240\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation Avg Loss: 0.017917\n",
      "*** New best model saved with Validation Loss 0.017917 at Epoch 2 ***\n",
      "Epoch 2 completed in 0:02:15\n",
      "\n",
      "Epoch 3/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training Avg Loss: 0.018895\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation Avg Loss: 0.017140\n",
      "*** New best model saved with Validation Loss 0.017140 at Epoch 3 ***\n",
      "Epoch 3 completed in 0:02:26\n",
      "\n",
      "Epoch 4/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training Avg Loss: 0.015055\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation Avg Loss: 0.014204\n",
      "*** New best model saved with Validation Loss 0.014204 at Epoch 5 ***\n",
      "Epoch 5 completed in 0:02:16\n",
      "\n",
      "Epoch 6/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training Avg Loss: 0.014571\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation Avg Loss: 0.014324\n",
      "Epoch 6 completed in 0:02:18\n",
      "\n",
      "Epoch 7/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training Avg Loss: 0.013549\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation Avg Loss: 0.012837\n",
      "*** New best model saved with Validation Loss 0.012837 at Epoch 7 ***\n",
      "Epoch 7 completed in 0:02:16\n",
      "\n",
      "Epoch 8/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training Avg Loss: 0.012938\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation Avg Loss: 0.011431\n",
      "*** New best model saved with Validation Loss 0.011431 at Epoch 8 ***\n",
      "Epoch 8 completed in 0:02:13\n",
      "\n",
      "Epoch 9/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training Avg Loss: 0.012282\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation Avg Loss: 0.011952\n",
      "Epoch 9 completed in 0:02:17\n",
      "\n",
      "Epoch 10/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training Avg Loss: 0.012194\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation Avg Loss: 0.012201\n",
      "Saved periodic checkpoint to /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/checkpoints/wavelet_unet_bn_epoch_010.pth\n",
      "Epoch 10 completed in 0:02:15\n",
      "\n",
      "Epoch 11/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training Avg Loss: 0.011794\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation Avg Loss: 0.011518\n",
      "Epoch 11 completed in 0:02:14\n",
      "\n",
      "Epoch 12/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training Avg Loss: 0.011499\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation Avg Loss: 0.010871\n",
      "*** New best model saved with Validation Loss 0.010871 at Epoch 12 ***\n",
      "Epoch 12 completed in 0:02:19\n",
      "\n",
      "Epoch 13/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training Avg Loss: 0.011179\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Validation Avg Loss: 0.010417\n",
      "*** New best model saved with Validation Loss 0.010417 at Epoch 13 ***\n",
      "Epoch 13 completed in 0:02:18\n",
      "\n",
      "Epoch 14/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training Avg Loss: 0.010910\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Validation Avg Loss: 0.010556\n",
      "Epoch 14 completed in 0:02:10\n",
      "\n",
      "Epoch 15/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training Avg Loss: 0.010787\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Validation Avg Loss: 0.011413\n",
      "Epoch 15 completed in 0:02:15\n",
      "\n",
      "Epoch 16/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training Avg Loss: 0.010369\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Validation Avg Loss: 0.010264\n",
      "*** New best model saved with Validation Loss 0.010264 at Epoch 16 ***\n",
      "Epoch 16 completed in 0:02:12\n",
      "\n",
      "Epoch 17/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training Avg Loss: 0.010567\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Validation Avg Loss: 0.010001\n",
      "*** New best model saved with Validation Loss 0.010001 at Epoch 17 ***\n",
      "Epoch 17 completed in 0:02:11\n",
      "\n",
      "Epoch 18/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training Avg Loss: 0.010278\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Validation Avg Loss: 0.009865\n",
      "*** New best model saved with Validation Loss 0.009865 at Epoch 18 ***\n",
      "Epoch 18 completed in 0:02:15\n",
      "\n",
      "Epoch 19/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training Avg Loss: 0.010189\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Validation Avg Loss: 0.009764\n",
      "*** New best model saved with Validation Loss 0.009764 at Epoch 19 ***\n",
      "Epoch 19 completed in 0:02:11\n",
      "\n",
      "Epoch 20/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training Avg Loss: 0.010088\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Validation Avg Loss: 0.009178\n",
      "*** New best model saved with Validation Loss 0.009178 at Epoch 20 ***\n",
      "Saved periodic checkpoint to /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/checkpoints/wavelet_unet_bn_epoch_020.pth\n",
      "Epoch 20 completed in 0:02:12\n",
      "\n",
      "Epoch 21/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training Avg Loss: 0.009679\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Validation Avg Loss: 0.009508\n",
      "Epoch 21 completed in 0:02:12\n",
      "\n",
      "Epoch 22/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training Avg Loss: 0.009765\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Validation Avg Loss: 0.009654\n",
      "Epoch 22 completed in 0:02:12\n",
      "\n",
      "Epoch 23/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training Avg Loss: 0.009426\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Validation Avg Loss: 0.008527\n",
      "*** New best model saved with Validation Loss 0.008527 at Epoch 23 ***\n",
      "Epoch 23 completed in 0:02:11\n",
      "\n",
      "Epoch 24/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training Avg Loss: 0.009258\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Validation Avg Loss: 0.009053\n",
      "Epoch 24 completed in 0:02:12\n",
      "\n",
      "Epoch 25/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training Avg Loss: 0.009437\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Validation Avg Loss: 0.008276\n",
      "*** New best model saved with Validation Loss 0.008276 at Epoch 25 ***\n",
      "Epoch 25 completed in 0:02:13\n",
      "\n",
      "Epoch 26/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training Avg Loss: 0.009506\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Validation Avg Loss: 0.009185\n",
      "Epoch 26 completed in 0:02:12\n",
      "\n",
      "Epoch 27/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training Avg Loss: 0.009144\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Validation Avg Loss: 0.009432\n",
      "Epoch 27 completed in 0:02:11\n",
      "\n",
      "Epoch 28/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training Avg Loss: 0.009037\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Validation Avg Loss: 0.008845\n",
      "Epoch 28 completed in 0:02:12\n",
      "\n",
      "Epoch 29/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training Avg Loss: 0.008914\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Validation Avg Loss: 0.008969\n",
      "Epoch 29 completed in 0:02:10\n",
      "\n",
      "Epoch 30/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training Avg Loss: 0.008770\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Validation Avg Loss: 0.009004\n",
      "Saved periodic checkpoint to /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/checkpoints/wavelet_unet_bn_epoch_030.pth\n",
      "Epoch 30 completed in 0:02:12\n",
      "\n",
      "Epoch 31/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training Avg Loss: 0.008692\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Validation Avg Loss: 0.008375\n",
      "Epoch 00031: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Learning rate reduced to 2.5e-04\n",
      "Epoch 31 completed in 0:02:13\n",
      "\n",
      "Epoch 32/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training Avg Loss: 0.008149\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Validation Avg Loss: 0.007928\n",
      "*** New best model saved with Validation Loss 0.007928 at Epoch 32 ***\n",
      "Epoch 32 completed in 0:02:12\n",
      "\n",
      "Epoch 33/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training Avg Loss: 0.008082\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Validation Avg Loss: 0.007865\n",
      "*** New best model saved with Validation Loss 0.007865 at Epoch 33 ***\n",
      "Epoch 33 completed in 0:02:12\n",
      "\n",
      "Epoch 34/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Training Avg Loss: 0.007904\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Validation Avg Loss: 0.007569\n",
      "*** New best model saved with Validation Loss 0.007569 at Epoch 34 ***\n",
      "Epoch 34 completed in 0:02:12\n",
      "\n",
      "Epoch 35/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training Avg Loss: 0.007799\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Validation Avg Loss: 0.007485\n",
      "*** New best model saved with Validation Loss 0.007485 at Epoch 35 ***\n",
      "Epoch 35 completed in 0:02:14\n",
      "\n",
      "Epoch 36/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training Avg Loss: 0.007908\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Validation Avg Loss: 0.008344\n",
      "Epoch 36 completed in 0:02:12\n",
      "\n",
      "Epoch 37/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Training Avg Loss: 0.007880\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Validation Avg Loss: 0.007644\n",
      "Epoch 37 completed in 0:02:12\n",
      "\n",
      "Epoch 38/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Training Avg Loss: 0.007918\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Validation Avg Loss: 0.008055\n",
      "Epoch 38 completed in 0:02:11\n",
      "\n",
      "Epoch 39/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Training Avg Loss: 0.007590\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Validation Avg Loss: 0.007317\n",
      "*** New best model saved with Validation Loss 0.007317 at Epoch 39 ***\n",
      "Epoch 39 completed in 0:02:13\n",
      "\n",
      "Epoch 40/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Training Avg Loss: 0.007844\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Validation Avg Loss: 0.007404\n",
      "Saved periodic checkpoint to /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/checkpoints/wavelet_unet_bn_epoch_040.pth\n",
      "Epoch 40 completed in 0:02:11\n",
      "\n",
      "Epoch 41/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Training Avg Loss: 0.007901\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Validation Avg Loss: 0.007589\n",
      "Epoch 41 completed in 0:02:12\n",
      "\n",
      "Epoch 42/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Training Avg Loss: 0.007701\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Validation Avg Loss: 0.007658\n",
      "Epoch 42 completed in 0:02:12\n",
      "\n",
      "Epoch 43/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Training Avg Loss: 0.007807\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Validation Avg Loss: 0.008181\n",
      "Epoch 43 completed in 0:02:11\n",
      "\n",
      "Epoch 44/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Training Avg Loss: 0.007520\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Validation Avg Loss: 0.007387\n",
      "Epoch 44 completed in 0:02:11\n",
      "\n",
      "Epoch 45/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training Avg Loss: 0.007470\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Validation Avg Loss: 0.007211\n",
      "*** New best model saved with Validation Loss 0.007211 at Epoch 45 ***\n",
      "Epoch 45 completed in 0:02:13\n",
      "\n",
      "Epoch 46/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Training Avg Loss: 0.007468\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Validation Avg Loss: 0.007309\n",
      "Epoch 46 completed in 0:02:11\n",
      "\n",
      "Epoch 47/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training Avg Loss: 0.007497\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Validation Avg Loss: 0.007256\n",
      "Epoch 47 completed in 0:02:11\n",
      "\n",
      "Epoch 48/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Training Avg Loss: 0.007369\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Validation Avg Loss: 0.007720\n",
      "Epoch 48 completed in 0:02:12\n",
      "\n",
      "Epoch 49/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Training Avg Loss: 0.007200\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Validation Avg Loss: 0.007233\n",
      "Epoch 49 completed in 0:02:11\n",
      "\n",
      "Epoch 50/50\n",
      "Training with 1000 samples (125 batches of size 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Training Avg Loss: 0.007413\n",
      "Validating with 200 samples (25 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Validation Avg Loss: 0.006904\n",
      "*** New best model saved with Validation Loss 0.006904 at Epoch 50 ***\n",
      "Saved periodic checkpoint to /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/checkpoints/wavelet_unet_bn_epoch_050.pth\n",
      "Epoch 50 completed in 0:02:11\n",
      "\n",
      "--- Training Finished ---\n",
      "Saved final model state to /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/wavelet_unet_bn_final.pth\n",
      "Saved loss curves plot to /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/loss_curves.png\n",
      "Best validation loss achieved: 0.006904\n",
      "Find best model at: /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/wavelet_unet_bn_best.pth\n",
      "Find final model at: /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/wavelet_unet_bn_final.pth\n",
      "Find training status log at: /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/train_status.csv\n",
      "Find sample montages in: /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/samples\n",
      "Find checkpoints in: /notebooks/output_3_18/smoke/output_V3_with_validation_FIXED/checkpoints\n",
      "\n",
      "--- Training script completed successfully! ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import pywt\n",
    "from tqdm import tqdm\n",
    "from pytorch_wavelets import DWTForward # Keep this for the loss\n",
    "import traceback\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys # Needed for sys.exit\n",
    "import matplotlib.pyplot as plt # Needed for plotting\n",
    "\n",
    "# Make sure training is reproducible\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Custom Dataset for Paired Smoky/Clear Images\n",
    "class ColonoscopyDataset(Dataset):\n",
    "    def __init__(self, clear_dir, blurry_dir, wavelet='db1'):\n",
    "        try:\n",
    "            # Load all files first\n",
    "            all_clear_files = sorted([f for f in os.listdir(clear_dir) if os.path.isfile(os.path.join(clear_dir, f))])\n",
    "            all_blurry_files = sorted([f for f in os.listdir(blurry_dir) if os.path.isfile(os.path.join(blurry_dir, f))])\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error accessing directories: {e}\")\n",
    "            raise e\n",
    "\n",
    "        if not all_clear_files or not all_blurry_files:\n",
    "            raise ValueError(f\"No files found in directories: Clear={len(all_clear_files)}, Blurry={len(all_blurry_files)}\")\n",
    "\n",
    "        min_len = min(len(all_clear_files), len(all_blurry_files))\n",
    "        if len(all_clear_files) != len(all_blurry_files):\n",
    "            print(f\"Warning: Mismatched file counts ({len(all_clear_files)} clear vs {len(all_blurry_files)} blurry). Using {min_len} pairs.\")\n",
    "            self.clear_files = all_clear_files[:min_len]\n",
    "            self.blurry_files = all_blurry_files[:min_len]\n",
    "        else:\n",
    "            self.clear_files = all_clear_files\n",
    "            self.blurry_files = all_blurry_files\n",
    "\n",
    "        self.total_samples = len(self.clear_files)\n",
    "        print(f\"Total paired samples available for this dataset instance: {self.total_samples}\") # Clarified print\n",
    "\n",
    "        self.clear_dir = clear_dir\n",
    "        self.blurry_dir = blurry_dir\n",
    "        self.wavelet = wavelet\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clear_files)\n",
    "\n",
    "    def get_filenames_by_index(self, idx):\n",
    "        if idx >= len(self.clear_files):\n",
    "            raise IndexError(f\"Index {idx} out of bounds for dataset size {len(self.clear_files)}\")\n",
    "        return self.clear_files[idx], self.blurry_files[idx]\n",
    "\n",
    "    def _load_and_preprocess_image(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            # Try adding common extensions if load fails initially\n",
    "            base, ext = os.path.splitext(img_path)\n",
    "            if not ext:\n",
    "                for try_ext in [\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\"]:\n",
    "                    try_path = img_path + try_ext\n",
    "                    if os.path.exists(try_path):\n",
    "                       img = cv2.imread(try_path)\n",
    "                       if img is not None:\n",
    "                           # print(f\"Successfully loaded {try_path}\") # Optional debug\n",
    "                           break\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Failed to load image: {img_path} (even with added extensions)\")\n",
    "\n",
    "        if len(img.shape) == 2: # Grayscale\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        elif img.shape[2] == 4: # BGRA\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "        elif img.shape[2] != 3: # Unexpected channels\n",
    "            raise ValueError(f\"Image {img_path} has unexpected shape {img.shape}\")\n",
    "\n",
    "        # Ensure output is RGB, float32, [0, 1] range\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            clear_file, blurry_file = self.get_filenames_by_index(idx)\n",
    "            clear_img_path = os.path.join(self.clear_dir, clear_file)\n",
    "            blurry_img_path = os.path.join(self.blurry_dir, blurry_file)\n",
    "\n",
    "            clear_img_np = self._load_and_preprocess_image(clear_img_path)\n",
    "            blurry_img_np = self._load_and_preprocess_image(blurry_img_path)\n",
    "\n",
    "            # Resize blurry to match clear if needed (important!)\n",
    "            if clear_img_np.shape[:2] != blurry_img_np.shape[:2]:\n",
    "                target_h, target_w = clear_img_np.shape[:2]\n",
    "                # print(f\"Warning: Resizing blurry image {blurry_file} from {blurry_img_np.shape[:2]} to match clear image {clear_file} { (target_h, target_w)}\") # Optional warning\n",
    "                blurry_img_np = cv2.resize(blurry_img_np, (target_w, target_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            clear_img_tensor = torch.from_numpy(clear_img_np).permute(2, 0, 1).float()\n",
    "            blurry_img_tensor = torch.from_numpy(blurry_img_np).permute(2, 0, 1).float()\n",
    "\n",
    "            return blurry_img_tensor, clear_img_tensor\n",
    "        except Exception as e:\n",
    "            print(f\"-----------------------------------\")\n",
    "            print(f\"FATAL Error loading item at index {idx}:\")\n",
    "            print(f\"Clear file attempted: {os.path.join(self.clear_dir, self.clear_files[idx]) if idx < len(self.clear_files) else 'Index out of bounds'}\")\n",
    "            print(f\"Blurry file attempted: {os.path.join(self.blurry_dir, self.blurry_files[idx]) if idx < len(self.blurry_files) else 'Index out of bounds'}\")\n",
    "            print(f\"Error details: {e}\")\n",
    "            traceback.print_exc()\n",
    "            print(f\"-----------------------------------\")\n",
    "            # Try returning a neighboring item or a dummy tensor to avoid crashing the loader if possible\n",
    "            # Return dummy tensor if error occurs, allowing training to continue potentially\n",
    "            # Adjust dummy shape if your images aren't 256x256\n",
    "            dummy_h, dummy_w = (256, 256)\n",
    "            if idx > 0:\n",
    "                try:\n",
    "                    print(f\"Attempting to return item at index {idx-1} instead.\")\n",
    "                    return self.__getitem__(idx-1)\n",
    "                except:\n",
    "                    print(f\"Fallback failed. Returning dummy tensor for index {idx}.\")\n",
    "                    dummy_tensor = torch.zeros((3, dummy_h, dummy_w), dtype=torch.float32)\n",
    "                    return dummy_tensor, dummy_tensor\n",
    "            else: # Error on item 0 itself\n",
    "                 print(f\"Error on first item (index 0). Returning dummy tensor.\")\n",
    "                 dummy_tensor = torch.zeros((3, dummy_h, dummy_w), dtype=torch.float32)\n",
    "                 return dummy_tensor, dummy_tensor\n",
    "\n",
    "# Wavelet-U-Net Model with BatchNorm\n",
    "class WaveletUNet_BN(nn.Module):\n",
    "    def __init__(self, in_channels=3, wavelet_channels=12): # wavelet_channels = C*4 = 3*4\n",
    "        super().__init__()\n",
    "        def conv_block(in_ch, out_ch):\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            # Initialize weights\n",
    "            for m in block.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            return block\n",
    "\n",
    "        self.enc1 = conv_block(in_channels, 64)           # Input: B, 3, H, W -> Output: B, 64, H, W\n",
    "        self.pool1 = nn.MaxPool2d(2)                       # -> B, 64, H/2, W/2\n",
    "        self.enc2 = conv_block(64, 128)                    # -> B, 128, H/2, W/2\n",
    "        self.pool2 = nn.MaxPool2d(2)                       # -> B, 128, H/4, W/4\n",
    "        self.enc3 = conv_block(128, 256)                   # -> B, 256, H/4, W/4\n",
    "        self.pool3 = nn.MaxPool2d(2)                       # -> B, 256, H/8, W/8\n",
    "        self.enc4 = conv_block(256, 512)                   # -> B, 512, H/8, W/8\n",
    "\n",
    "        # Wavelet feature pathway (operates on wavelet input [B, 12, H/2, W/2])\n",
    "        self.wavelet_enc1 = conv_block(wavelet_channels, 64) # Input: B, 12, H/2, W/2 -> Output: B, 64, H/2, W/2\n",
    "        self.pool_w1 = nn.MaxPool2d(2)                     # -> B, 64, H/4, W/4\n",
    "        self.wavelet_enc2 = conv_block(64, 128)            # -> B, 128, H/4, W/4\n",
    "\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) # Upsample e4: B, 512, H/4, W/4\n",
    "        # Concat: [up3(e4), e3, w_feat3] = [B, 512, H/4, W/4] + [B, 256, H/4, W/4] + [B, 128, H/4, W/4] = B, 896, H/4, W/4\n",
    "        self.dec3 = conv_block(512 + 256 + 128, 256)       # -> B, 256, H/4, W/4\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) # Upsample d3: B, 256, H/2, W/2\n",
    "        # Concat: [up2(d3), e2, w_feat2] = [B, 256, H/2, W/2] + [B, 128, H/2, W/2] + [B, 64, H/2, W/2] = B, 448, H/2, W/2\n",
    "        self.dec2 = conv_block(256 + 128 + 64, 128)        # -> B, 128, H/2, W/2\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) # Upsample d2: B, 128, H, W\n",
    "        # Concat: [up1(d2), e1] = [B, 128, H, W] + [B, 64, H, W] = B, 192, H, W\n",
    "        self.dec1 = conv_block(128 + 64, 64)               # -> B, 64, H, W\n",
    "\n",
    "        self.final = nn.Conv2d(64, 3, kernel_size=1)       # -> B, 3, H, W\n",
    "        # Init final layer weights\n",
    "        nn.init.kaiming_normal_(self.final.weight, mode='fan_out', nonlinearity='linear')\n",
    "        if self.final.bias is not None: nn.init.constant_(self.final.bias, 0)\n",
    "\n",
    "    def forward(self, x, wavelet):\n",
    "        # Encoder path\n",
    "        e1 = self.enc1(x);          # B, 64, H, W\n",
    "        p1 = self.pool1(e1);        # B, 64, H/2, W/2\n",
    "        e2 = self.enc2(p1);         # B, 128, H/2, W/2\n",
    "        p2 = self.pool2(e2);        # B, 128, H/4, W/4\n",
    "        e3 = self.enc3(p2);         # B, 256, H/4, W/4\n",
    "        p3 = self.pool3(e3);        # B, 256, H/8, W/8\n",
    "        e4 = self.enc4(p3);         # B, 512, H/8, W/8\n",
    "\n",
    "        # Wavelet feature path\n",
    "        w_feat2 = self.wavelet_enc1(wavelet) # B, 64, H/2, W/2 (Matches e2 size)\n",
    "        pw_feat2 = self.pool_w1(w_feat2)   # B, 64, H/4, W/4\n",
    "        w_feat3 = self.wavelet_enc2(pw_feat2)  # B, 128, H/4, W/4 (Matches e3 size)\n",
    "\n",
    "        # Decoder path with skip connections and wavelet features\n",
    "        up3 = self.up3(e4);         # B, 512, H/4, W/4\n",
    "        cat3 = torch.cat([up3, e3, w_feat3], dim=1); # B, 512+256+128=896, H/4, W/4\n",
    "        d3 = self.dec3(cat3);       # B, 256, H/4, W/4\n",
    "\n",
    "        up2 = self.up2(d3);         # B, 256, H/2, W/2\n",
    "        cat2 = torch.cat([up2, e2, w_feat2], dim=1); # B, 256+128+64=448, H/2, W/2\n",
    "        d2 = self.dec2(cat2);       # B, 128, H/2, W/2\n",
    "\n",
    "        up1 = self.up1(d2);         # B, 128, H, W\n",
    "        cat1 = torch.cat([up1, e1], dim=1); # B, 128+64=192, H, W\n",
    "        d1 = self.dec1(cat1);       # B, 64, H, W\n",
    "\n",
    "        out = self.final(d1);       # B, 3, H, W\n",
    "        return torch.sigmoid(out) # Output in [0, 1] range\n",
    "\n",
    "# Combined Loss with Differentiable DWT\n",
    "class CombinedLossDWT(nn.Module):\n",
    "    def __init__(self, alpha=0.85, wavelet='db1', device='cpu'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        # Ensure DWTForward is created only once and on the correct device\n",
    "        try:\n",
    "            self.dwt = DWTForward(J=1, wave=wavelet, mode='symmetric').to(device)\n",
    "            self._dwt_initialized = True\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR initializing DWTForward: {e}. Frequency loss will be disabled.\")\n",
    "            self._dwt_initialized = False\n",
    "        self.device = device\n",
    "\n",
    "    def _compute_dwt(self, x):\n",
    "        # Input x shape: [B, C, H, W]\n",
    "        x = x.to(self.device) # Ensure input is on the correct device\n",
    "        LL, H_coeffs = self.dwt(x)\n",
    "        # LL shape: [B, C, H/2, W/2]\n",
    "        # H_coeffs is a list containing one tensor for J=1\n",
    "        # H_coeffs[0] shape: [B, C, 3, H/2, W/2] where 3 is for LH, HL, HH\n",
    "        details = H_coeffs[0]\n",
    "        B, C, _, H_d, W_d = details.shape\n",
    "\n",
    "        # Reshape details: [B, C, 3, H/2, W/2] -> [B, C*3, H/2, W/2]\n",
    "        details_reshaped = details.reshape(B, C * 3, H_d, W_d)\n",
    "\n",
    "        # Concatenate along channel dimension: [B, C + C*3, H/2, W/2] = [B, 4*C, H/2, W/2]\n",
    "        coeffs_combined = torch.cat([LL, details_reshaped], dim=1)\n",
    "        return coeffs_combined\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred, target = pred.float().to(self.device), target.float().to(self.device) # Ensure on correct device\n",
    "        spatial_loss = self.l1_loss(pred, target)\n",
    "\n",
    "        # Compute DWT only if alpha < 1 and DWT was initialized\n",
    "        if self.alpha < 1.0 and self._dwt_initialized:\n",
    "            try:\n",
    "                pred_wavelet = self._compute_dwt(pred)\n",
    "                target_wavelet = self._compute_dwt(target)\n",
    "                freq_loss = self.l1_loss(pred_wavelet, target_wavelet)\n",
    "            except Exception as e:\n",
    "                 print(f\"Warning: Error computing DWT loss during forward pass: {e}. Setting freq_loss to 0 for this batch.\")\n",
    "                 # traceback.print_exc() # Optional: more detail\n",
    "                 freq_loss = torch.tensor(0.0, device=self.device) # Avoid crashing if DWT fails\n",
    "        else:\n",
    "            freq_loss = torch.tensor(0.0, device=self.device) # No frequency loss if alpha is 1 or DWT failed init\n",
    "\n",
    "        total_loss = self.alpha * spatial_loss + (1 - self.alpha) * freq_loss\n",
    "\n",
    "        # Check for NaN loss RIGHT BEFORE returning\n",
    "        if torch.isnan(total_loss):\n",
    "            print(f\"NaN loss detected! Spatial: {spatial_loss.item():.6f}, Freq: {freq_loss.item():.6f}, Alpha: {self.alpha}\")\n",
    "            print(\"Check input data, model outputs, or DWT calculations.\")\n",
    "            # Return a large finite loss to allow scheduler/logging but indicate error\n",
    "            # Make sure it requires grad if backprop is expected\n",
    "            return torch.tensor(1000.0, device=self.device, requires_grad=True)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "# Helper function for non-differentiable wavelet INPUT generation (using pywt)\n",
    "def get_wavelet_input(img_tensor, wavelet='db1', device='cpu'):\n",
    "    # Input: img_tensor [B, C, H, W]\n",
    "    if not isinstance(img_tensor, torch.Tensor):\n",
    "        raise TypeError(f\"Expected img_tensor to be a torch.Tensor, got {type(img_tensor)}\")\n",
    "    if img_tensor.ndim != 4:\n",
    "         raise ValueError(f\"Expected img_tensor to have 4 dimensions [B, C, H, W], got shape {img_tensor.shape}\")\n",
    "\n",
    "    B, C, H, W = img_tensor.shape\n",
    "    # Ensure tensor is on CPU for numpy conversion\n",
    "    img_np = img_tensor.detach().cpu().numpy().transpose(0, 2, 3, 1) # -> [B, H, W, C]\n",
    "    batch_wavelets = []\n",
    "    # Target size for wavelet coefficients (H/2, W/2)\n",
    "    target_h_half, target_w_half = H // 2, W // 2\n",
    "    target_ch_out = C * 4 # LL, LH, HL, HH for each input channel C\n",
    "\n",
    "    for i in range(img_np.shape[0]): # Iterate through batch\n",
    "        single_img_np = img_np[i] # H, W, C\n",
    "        if not np.isfinite(single_img_np).all():\n",
    "             print(f\"Warning: Non-finite values detected in input image at batch index {i}. Replacing with zeros before DWT.\")\n",
    "             single_img_np = np.nan_to_num(single_img_np) # Replace NaN/inf with 0\n",
    "\n",
    "        try:\n",
    "            # Perform 2D DWT on each channel separately? No, pywt handles multichannel via axes\n",
    "            # axes=(-3, -2) should correspond to H, W dimensions in (H, W, C)\n",
    "            coeffs = pywt.dwt2(single_img_np, wavelet, mode='symmetric', axes=(0, 1))\n",
    "            cA, (cH, cV, cD) = coeffs\n",
    "            # cA, cH, cV, cD will have shape like [H/2, W/2, C]\n",
    "\n",
    "            # Concatenate along the channel dimension (axis=2)\n",
    "            # Result shape: [H/2, W/2, 4*C]\n",
    "            wavelet_np = np.concatenate([cA, cH, cV, cD], axis=2).astype(np.float32)\n",
    "\n",
    "            # Handle potential size mismatches due to odd dimensions in DWT\n",
    "            h_np, w_np = wavelet_np.shape[:2]\n",
    "            if h_np != target_h_half or w_np != target_w_half:\n",
    "                 # print(f\"Warning: Resizing pywt output from {(h_np, w_np)} to {(target_h_half, target_w_half)} for batch item {i}\") # Optional warning\n",
    "                 # Resize requires (width, height) order for cv2\n",
    "                 wavelet_np = cv2.resize(wavelet_np, (target_w_half, target_h_half), interpolation=cv2.INTER_LINEAR)\n",
    "                 # If resize squashes channels (e.g., single channel input), restore dim\n",
    "                 if wavelet_np.ndim == 2: wavelet_np = wavelet_np[:, :, np.newaxis]\n",
    "                 # Check channel count after potential resize (unlikely to change but defensive)\n",
    "                 if wavelet_np.shape[2] != target_ch_out:\n",
    "                     print(f\"FATAL: Wavelet channel mismatch after resize ({wavelet_np.shape[2]} vs {target_ch_out}). This should not happen.\")\n",
    "                     # Fallback: create zeros of correct shape\n",
    "                     wavelet_np = np.zeros((target_h_half, target_w_half, target_ch_out), dtype=np.float32)\n",
    "\n",
    "\n",
    "            # Normalize wavelet coefficients (per channel within the 4*C channels)\n",
    "            for ch in range(wavelet_np.shape[2]):\n",
    "                channel_data = wavelet_np[:, :, ch]\n",
    "                mean = channel_data.mean()\n",
    "                std = channel_data.std()\n",
    "                wavelet_np[:, :, ch] = (channel_data - mean) / (std + 1e-8) # Add epsilon for stability\n",
    "\n",
    "            batch_wavelets.append(wavelet_np)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"-----------------------------------\")\n",
    "            print(f\"Error generating pywt input for batch item {i}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            print(f\"Input image shape: {single_img_np.shape}\")\n",
    "            print(f\"Using zeros as fallback for this item.\")\n",
    "            print(f\"-----------------------------------\")\n",
    "            # Use zeros if pywt fails for an item\n",
    "            zero_wavelet = np.zeros((target_h_half, target_w_half, target_ch_out), dtype=np.float32)\n",
    "            batch_wavelets.append(zero_wavelet)\n",
    "\n",
    "    # Stack the processed wavelets into a single batch numpy array\n",
    "    wavelet_batch_np = np.stack(batch_wavelets) # [B, H/2, W/2, 4*C]\n",
    "    # Permute to PyTorch format [B, C', H', W'] where C'=4*C, H'=H/2, W'=W/2\n",
    "    wavelet_tensor = torch.from_numpy(wavelet_batch_np).permute(0, 3, 1, 2).float()\n",
    "    return wavelet_tensor.to(device)\n",
    "\n",
    "# Utility function to convert tensor batch to visualizable numpy images\n",
    "def tensors_to_cv2_images(tensor_batch):\n",
    "    \"\"\" Converts a batch of [B, C, H, W] tensors (range [0,1]) to list of OpenCV images (BGR, uint8). \"\"\"\n",
    "    images = []\n",
    "    if tensor_batch is None: return images # Handle None input\n",
    "    if not isinstance(tensor_batch, torch.Tensor): return images # Handle non-tensor input\n",
    "\n",
    "    tensor_batch = tensor_batch.detach().cpu() # Move to CPU and detach from graph\n",
    "    for i in range(tensor_batch.shape[0]):\n",
    "        img_tensor = tensor_batch[i] # Get single image tensor [C, H, W]\n",
    "        # Ensure 3 channels for color conversion\n",
    "        if img_tensor.shape[0] == 1: # Grayscale tensor\n",
    "             img_tensor = img_tensor.repeat(3, 1, 1) # Convert to 3 channels\n",
    "        elif img_tensor.shape[0] != 3:\n",
    "             print(f\"Warning: tensor_to_cv2_images expects 3 channels, got {img_tensor.shape[0]}. Skipping item {i}.\")\n",
    "             continue\n",
    "\n",
    "        img_np = img_tensor.numpy().transpose(1, 2, 0) # Convert to H, W, C (NumPy format)\n",
    "        img_np = np.clip(img_np, 0, 1) # Ensure range [0, 1] after potential model overshoot\n",
    "        img_uint8 = (img_np * 255).astype(np.uint8) # Convert to uint8 [0, 255]\n",
    "        img_bgr = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR) # Convert RGB -> BGR for OpenCV saving\n",
    "        images.append(img_bgr)\n",
    "    return images\n",
    "\n",
    "# Evaluate model on a batch of images (used potentially for validation samples)\n",
    "def evaluate_batch(model, criterion, blurry_batch, clear_batch, device, wavelet='db1'):\n",
    "    \"\"\"Evaluates the model on a single batch and returns loss and predictions.\"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    with torch.no_grad(): # Disable gradient calculation\n",
    "        # Ensure data is on the correct device\n",
    "        blurry_batch = blurry_batch.to(device)\n",
    "        clear_batch = clear_batch.to(device)\n",
    "\n",
    "        # Generate wavelet input\n",
    "        wavelet_batch = get_wavelet_input(blurry_batch, wavelet=wavelet, device=device)\n",
    "\n",
    "        # Get model predictions\n",
    "        predictions = model(blurry_batch, wavelet_batch)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(predictions, clear_batch).item() # .item() gets scalar value\n",
    "\n",
    "    # Return model to training mode? No, let the caller handle it.\n",
    "    return loss, predictions\n",
    "\n",
    "# Function to create a montage of sample images\n",
    "def create_sample_montage(blurry_batch, pred_batch, clear_batch, sample_indices):\n",
    "    \"\"\"Creates a 3-row montage: Ground Truth, Prediction, Blurry Input.\"\"\"\n",
    "    # Convert tensors to OpenCV images (list of BGR uint8 numpy arrays)\n",
    "    clear_cv2 = tensors_to_cv2_images(clear_batch)    # Row 1: Ground Truth\n",
    "    pred_cv2 = tensors_to_cv2_images(pred_batch)      # Row 2: Model Output\n",
    "    blurry_cv2 = tensors_to_cv2_images(blurry_batch)  # Row 3: Blurry Input\n",
    "\n",
    "    # Check if conversion yielded any images\n",
    "    if not clear_cv2 or not pred_cv2 or not blurry_cv2:\n",
    "        print(\"Warning: Failed to convert one or more tensor batches to CV2 images for montage.\")\n",
    "        return None\n",
    "\n",
    "    # Determine target size for consistency (use prediction size as reference)\n",
    "    target_h, target_w = pred_cv2[0].shape[:2]\n",
    "\n",
    "    # Resize function (ensure consistent dimensions for hconcat/vconcat)\n",
    "    def resize_img_list(img_list, target_w, target_h):\n",
    "        resized_list = []\n",
    "        for img in img_list:\n",
    "            if img is None: continue # Skip None images\n",
    "            if img.shape[:2] != (target_h, target_w):\n",
    "                try:\n",
    "                    resized_img = cv2.resize(img, (target_w, target_h), interpolation=cv2.INTER_LINEAR)\n",
    "                    resized_list.append(resized_img)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to resize image in montage: {e}\")\n",
    "            else:\n",
    "                resized_list.append(img)\n",
    "        return resized_list\n",
    "\n",
    "    # Resize all image lists\n",
    "    resized_clear = resize_img_list(clear_cv2, target_w, target_h)\n",
    "    resized_pred = resize_img_list(pred_cv2, target_w, target_h)\n",
    "    resized_blurry = resize_img_list(blurry_cv2, target_w, target_h)\n",
    "\n",
    "    # Check if we still have images after resizing\n",
    "    if not resized_clear or not resized_pred or not resized_blurry:\n",
    "         print(\"Warning: One or more image lists became empty after resizing for montage.\")\n",
    "         return None\n",
    "    # Ensure all lists have the same number of images after potential resize failures?\n",
    "    # For simplicity, we'll assume they match the number of predictions if resizing worked.\n",
    "    num_images = len(resized_pred)\n",
    "    resized_clear = resized_clear[:num_images]\n",
    "    resized_blurry = resized_blurry[:num_images]\n",
    "\n",
    "\n",
    "    # Add index labels to images\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.6 # Slightly larger font\n",
    "    thickness = 1\n",
    "    text_color = (255, 255, 255)  # White\n",
    "    bg_color = (0, 0, 0) # Black background for text\n",
    "    text_y_offset = 20\n",
    "    label_y_offset = 45\n",
    "\n",
    "    for i in range(num_images):\n",
    "        if i < len(sample_indices): # Check index validity\n",
    "            idx_text = f\"Orig Idx: {sample_indices[i]}\"\n",
    "\n",
    "            # Add text with background rectangle for better visibility\n",
    "            def add_text_with_bg(img, text, org_y, scale=font_scale, thickness=thickness):\n",
    "                 (text_width, text_height), _ = cv2.getTextSize(text, font, scale, thickness)\n",
    "                 cv2.rectangle(img, (5, org_y - text_height - 2), (5 + text_width + 4, org_y + 4), bg_color, -1)\n",
    "                 cv2.putText(img, text, (7, org_y), font, scale, text_color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            # Add labels to each image in the row\n",
    "            add_text_with_bg(resized_clear[i], \"Ground Truth\", text_y_offset)\n",
    "            add_text_with_bg(resized_clear[i], idx_text, label_y_offset)\n",
    "\n",
    "            add_text_with_bg(resized_pred[i], \"Prediction\", text_y_offset)\n",
    "            add_text_with_bg(resized_pred[i], idx_text, label_y_offset)\n",
    "\n",
    "            add_text_with_bg(resized_blurry[i], \"Blurry Input\", text_y_offset)\n",
    "            add_text_with_bg(resized_blurry[i], idx_text, label_y_offset)\n",
    "        else:\n",
    "             print(f\"Warning: Not enough sample indices provided ({len(sample_indices)}) for image {i} in montage.\")\n",
    "\n",
    "    # Create the montage by horizontally concatenating images in each row\n",
    "    try:\n",
    "        row1 = cv2.hconcat(resized_clear)  # Ground Truth\n",
    "        row2 = cv2.hconcat(resized_pred)   # Model Output\n",
    "        row3 = cv2.hconcat(resized_blurry) # Blurry Input\n",
    "\n",
    "        # Add padding between rows\n",
    "        padding_h = 10\n",
    "        # Ensure padding width matches the concatenated row width\n",
    "        padding = np.zeros((padding_h, row1.shape[1], 3), dtype=np.uint8) # Black padding\n",
    "\n",
    "        # Stack rows vertically: Truth, Padding, Prediction, Padding, Blurry\n",
    "        montage = cv2.vconcat([row1, padding.copy(), row2, padding.copy(), row3])\n",
    "        return montage\n",
    "\n",
    "    except Exception as e:\n",
    "         print(f\"Error during hconcat/vconcat for montage: {e}\")\n",
    "         print(f\"Shapes - Clear: {[img.shape for img in resized_clear]}, Pred: {[img.shape for img in resized_pred]}, Blurry: {[img.shape for img in resized_blurry]}\")\n",
    "         traceback.print_exc()\n",
    "         return None\n",
    "\n",
    "# --- Training Function ---\n",
    "def train_model(clear_dir, blurry_dir, output_dir, epochs=50, batch_size=8, lr=0.0005,\n",
    "                wavelet='db1', alpha=0.85, weight_decay=1e-5,\n",
    "                train_samples_per_epoch=1000, # Max samples for training subset per epoch\n",
    "                val_samples_per_epoch=100,    # Max samples for validation subset per epoch\n",
    "                train_val_split=0.8, random_seed=42, num_workers=None):\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(random_seed) # for multi-GPU\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize full dataset\n",
    "    try:\n",
    "        full_dataset = ColonoscopyDataset(clear_dir, blurry_dir, wavelet=wavelet)\n",
    "        total_samples = len(full_dataset)\n",
    "        if total_samples == 0:\n",
    "            raise ValueError(\"Dataset is empty! Check clear/blurry directories and file pairing.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing dataset: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "    # Create train/validation split indices\n",
    "    indices = list(range(total_samples))\n",
    "    random.shuffle(indices) # Shuffle indices before splitting\n",
    "    split_point = int(total_samples * train_val_split)\n",
    "    train_indices = indices[:split_point]\n",
    "    val_indices = indices[split_point:]\n",
    "\n",
    "    # Handle cases where requested samples per epoch exceed available data\n",
    "    num_train_available = len(train_indices)\n",
    "    num_val_available = len(val_indices)\n",
    "    actual_train_samples_per_epoch = min(train_samples_per_epoch, num_train_available)\n",
    "    actual_val_samples_per_epoch = min(val_samples_per_epoch, num_val_available)\n",
    "\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Train/Val split: {num_train_available}/{num_val_available} ({train_val_split*100:.1f}% / {(1-train_val_split)*100:.1f}%)\")\n",
    "    print(f\"Using {actual_train_samples_per_epoch} train samples per epoch (requested: {train_samples_per_epoch})\")\n",
    "    print(f\"Using {actual_val_samples_per_epoch} val samples per epoch (requested: {val_samples_per_epoch})\")\n",
    "    if num_train_available == 0 or num_val_available == 0:\n",
    "         print(\"ERROR: Training or validation set has 0 samples after split. Cannot proceed.\")\n",
    "         return None\n",
    "\n",
    "    # Create model, optimizer, and loss function\n",
    "    model = WaveletUNet_BN().to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = CombinedLossDWT(alpha=alpha, wavelet=wavelet, device=device)\n",
    "    # Reduce LR if val loss plateaus for 'patience' epochs\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "    # Create output directories\n",
    "    samples_dir = os.path.join(output_dir, \"samples\")\n",
    "    checkpoints_dir = os.path.join(output_dir, \"checkpoints\")\n",
    "    os.makedirs(samples_dir, exist_ok=True)\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "\n",
    "    # Create CSV file for training/validation loss tracking\n",
    "    csv_path = os.path.join(output_dir, \"train_status.csv\")\n",
    "    try:\n",
    "        with open(csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['Epoch', 'Training Loss', 'Validation Loss', 'Learning Rate', 'Timestamp'])\n",
    "    except IOError as e:\n",
    "        print(f\"Error creating CSV log file {csv_path}: {e}\")\n",
    "        return None # Stop if we can't log\n",
    "\n",
    "    # Best model tracking\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = os.path.join(output_dir, \"wavelet_unet_bn_best.pth\") # Defined outside loop\n",
    "\n",
    "    # Determine num_workers\n",
    "    if num_workers is None:\n",
    "        num_workers = min(4, os.cpu_count() // 2 if os.cpu_count() is not None and os.cpu_count() > 1 else 1)\n",
    "        print(f\"Auto-detected num_workers: {num_workers}\")\n",
    "    else:\n",
    "        print(f\"Using specified num_workers: {num_workers}\")\n",
    "\n",
    "\n",
    "    print(f\"\\n--- Starting Training for {epochs} epochs ---\")\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = datetime.now()\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        # ===== TRAINING PHASE =====\n",
    "        model.train() # Set model to training mode\n",
    "        train_running_loss = 0.0\n",
    "        processed_train_samples = 0\n",
    "\n",
    "        # Randomly sample indices for THIS epoch's training subset\n",
    "        epoch_train_indices = random.sample(train_indices, actual_train_samples_per_epoch)\n",
    "        train_subset = Subset(full_dataset, epoch_train_indices)\n",
    "        # pin_memory=True can speed up CPU->GPU transfer if using CUDA\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True,\n",
    "                                 num_workers=num_workers, pin_memory=(device.type == 'cuda'), drop_last=True)\n",
    "\n",
    "        print(f\"Training with {len(epoch_train_indices)} samples ({len(train_loader)} batches of size {batch_size})\")\n",
    "\n",
    "        # Training loop with progress bar\n",
    "        train_progress = tqdm(train_loader, desc=f\"Train E{epoch+1}\", leave=False, unit=\"batch\")\n",
    "        for i, batch in enumerate(train_progress):\n",
    "            try:\n",
    "                blurry_img, clear_img = batch\n",
    "                # Skip if batch is None or tensors are invalid (e.g., from dummy data)\n",
    "                if blurry_img is None or clear_img is None or not isinstance(blurry_img, torch.Tensor) or not isinstance(clear_img, torch.Tensor):\n",
    "                     print(f\"Warning: Skipping invalid batch {i} in training.\")\n",
    "                     continue\n",
    "                if blurry_img.shape[0] == 0 or clear_img.shape[0] == 0:\n",
    "                     print(f\"Warning: Skipping empty batch {i} in training.\")\n",
    "                     continue\n",
    "\n",
    "                blurry_img = blurry_img.to(device, non_blocking=True)\n",
    "                clear_img = clear_img.to(device, non_blocking=True)\n",
    "\n",
    "                # Generate wavelet input for the blurry image batch\n",
    "                wavelet_input = get_wavelet_input(blurry_img, wavelet=wavelet, device=device)\n",
    "\n",
    "                # --- Forward pass ---\n",
    "                optimizer.zero_grad() # Reset gradients before forward pass\n",
    "                predictions = model(blurry_img, wavelet_input)\n",
    "\n",
    "                # --- Calculate Loss ---\n",
    "                loss = criterion(predictions, clear_img)\n",
    "\n",
    "                # Skip batch if loss is NaN (potentially from bad data or DWT issues)\n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"\\nWarning: NaN loss detected in training batch {i}. Skipping backward/step.\")\n",
    "                    optimizer.zero_grad() # Ensure grads are zeroed if skipping step\n",
    "                    continue # Skip backward and step\n",
    "\n",
    "                # --- Backward pass ---\n",
    "                loss.backward()\n",
    "\n",
    "                # Optional: Gradient clipping (uncomment if needed for stability)\n",
    "                # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "                # --- Optimizer step ---\n",
    "                optimizer.step()\n",
    "\n",
    "                # --- Update metrics ---\n",
    "                current_loss = loss.item()\n",
    "                batch_sample_count = blurry_img.size(0)\n",
    "                train_running_loss += current_loss * batch_sample_count # Weighted by batch size\n",
    "                processed_train_samples += batch_sample_count\n",
    "\n",
    "                # Update progress bar description\n",
    "                train_progress.set_postfix(loss=f\"{current_loss:.6f}\",\n",
    "                                          avg_loss=f\"{train_running_loss/processed_train_samples:.6f}\",\n",
    "                                          lr=f\"{optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n-----------------------------------\")\n",
    "                print(f\"ERROR in training batch {i} (Epoch {epoch+1}): {e}\")\n",
    "                print(f\"Batch blurry shape: {blurry_img.shape if 'blurry_img' in locals() and isinstance(blurry_img, torch.Tensor) else 'N/A'}\")\n",
    "                print(f\"Batch clear shape: {clear_img.shape if 'clear_img' in locals() and isinstance(clear_img, torch.Tensor) else 'N/A'}\")\n",
    "                traceback.print_exc()\n",
    "                print(f\"-----------------------------------\")\n",
    "                continue # Continue to next batch if one fails\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        train_loss = train_running_loss / processed_train_samples if processed_train_samples > 0 else float('inf')\n",
    "        print(f\"Epoch {epoch+1} Training Avg Loss: {train_loss:.6f}\")\n",
    "\n",
    "\n",
    "        # ===== VALIDATION PHASE =====\n",
    "        model.eval() # Set model to evaluation mode\n",
    "        val_running_loss = 0.0\n",
    "        processed_val_samples = 0\n",
    "\n",
    "        # Randomly sample indices for THIS epoch's validation subset\n",
    "        epoch_val_indices = random.sample(val_indices, actual_val_samples_per_epoch)\n",
    "        val_subset = Subset(full_dataset, epoch_val_indices)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, # No shuffle for validation\n",
    "                               num_workers=num_workers, pin_memory=(device.type == 'cuda'), drop_last=False) # Don't drop last val batch\n",
    "\n",
    "        print(f\"Validating with {len(epoch_val_indices)} samples ({len(val_loader)} batches)\")\n",
    "\n",
    "        # Keep track of the first few validation samples for visualization\n",
    "        vis_blurry_batch = None\n",
    "        vis_clear_batch = None\n",
    "        vis_pred_batch = None\n",
    "        # Take indices corresponding to the *first validation batch* or up to 5 samples\n",
    "        vis_indices = epoch_val_indices[:min(batch_size, 5)]\n",
    "\n",
    "        # Validation loop with progress bar\n",
    "        val_progress = tqdm(val_loader, desc=f\"Validate E{epoch+1}\", leave=False, unit=\"batch\")\n",
    "        with torch.no_grad(): # Disable gradient calculations for validation\n",
    "            for i, batch in enumerate(val_progress):\n",
    "                try:\n",
    "                    blurry_img, clear_img = batch\n",
    "                    if blurry_img is None or clear_img is None or not isinstance(blurry_img, torch.Tensor) or not isinstance(clear_img, torch.Tensor):\n",
    "                         print(f\"Warning: Skipping invalid batch {i} in validation.\")\n",
    "                         continue\n",
    "                    if blurry_img.shape[0] == 0 or clear_img.shape[0] == 0:\n",
    "                         print(f\"Warning: Skipping empty batch {i} in validation.\")\n",
    "                         continue\n",
    "\n",
    "                    blurry_img = blurry_img.to(device, non_blocking=True)\n",
    "                    clear_img = clear_img.to(device, non_blocking=True)\n",
    "\n",
    "                    # Save first batch for visualization (match size of vis_indices)\n",
    "                    if i == 0 and len(blurry_img) > 0:\n",
    "                        num_to_vis = min(len(blurry_img), len(vis_indices))\n",
    "                        vis_blurry_batch = blurry_img[:num_to_vis]\n",
    "                        vis_clear_batch = clear_img[:num_to_vis]\n",
    "                        # Update vis_indices to reflect actual indices used if batch was smaller\n",
    "                        vis_indices = epoch_val_indices[:num_to_vis]\n",
    "\n",
    "\n",
    "                    # Wavelet preprocessing and forward pass\n",
    "                    wavelet_input = get_wavelet_input(blurry_img, wavelet=wavelet, device=device)\n",
    "                    predictions = model(blurry_img, wavelet_input)\n",
    "\n",
    "                    # Save predictions corresponding to the first batch\n",
    "                    if i == 0 and vis_blurry_batch is not None:\n",
    "                        vis_pred_batch = predictions[:len(vis_indices)] # Match size\n",
    "\n",
    "                    # --- Calculate validation loss ---\n",
    "                    val_loss_batch = criterion(predictions, clear_img)\n",
    "\n",
    "                    if torch.isnan(val_loss_batch):\n",
    "                         print(f\"\\nWarning: NaN loss detected in validation batch {i}. Skipping.\")\n",
    "                         continue\n",
    "\n",
    "                    # --- Update validation metrics ---\n",
    "                    current_val_loss = val_loss_batch.item()\n",
    "                    batch_sample_count = blurry_img.size(0)\n",
    "                    val_running_loss += current_val_loss * batch_sample_count # Weighted by batch size\n",
    "                    processed_val_samples += batch_sample_count\n",
    "\n",
    "                    # Update progress bar\n",
    "                    val_progress.set_postfix(loss=f\"{current_val_loss:.6f}\",\n",
    "                                           avg_loss=f\"{val_running_loss/processed_val_samples:.6f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n-----------------------------------\")\n",
    "                    print(f\"ERROR in validation batch {i} (Epoch {epoch+1}): {e}\")\n",
    "                    print(f\"Batch blurry shape: {blurry_img.shape if 'blurry_img' in locals() and isinstance(blurry_img, torch.Tensor) else 'N/A'}\")\n",
    "                    print(f\"Batch clear shape: {clear_img.shape if 'clear_img' in locals() and isinstance(clear_img, torch.Tensor) else 'N/A'}\")\n",
    "                    traceback.print_exc()\n",
    "                    print(f\"-----------------------------------\")\n",
    "                    continue # Continue validation if one batch fails\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        val_loss = val_running_loss / processed_val_samples if processed_val_samples > 0 else float('inf')\n",
    "        print(f\"Epoch {epoch+1} Validation Avg Loss: {val_loss:.6f}\")\n",
    "\n",
    "        # --- Post-Epoch Actions ---\n",
    "\n",
    "        # Update learning rate scheduler based on validation loss\n",
    "        current_lr = optimizer.param_groups[0]['lr'] # Get LR before scheduler step\n",
    "        scheduler.step(val_loss)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if new_lr < current_lr:\n",
    "             print(f\"Learning rate reduced to {new_lr:.1e}\")\n",
    "\n",
    "        # Log metrics to CSV\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        try:\n",
    "            with open(csv_path, 'a', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow([\n",
    "                    epoch + 1,\n",
    "                    f\"{train_loss:.6f}\" if train_loss != float('inf') else 'N/A', # Handle potential inf\n",
    "                    f\"{val_loss:.6f}\" if val_loss != float('inf') else 'N/A', # Handle potential inf\n",
    "                    f\"{current_lr:.6f}\", # Log LR used *during* the epoch\n",
    "                    timestamp\n",
    "                ])\n",
    "        except IOError as e:\n",
    "             print(f\"Warning: Could not write to CSV log file {csv_path}: {e}\")\n",
    "\n",
    "        # Create and save sample visualization montage from the validation set\n",
    "        if vis_blurry_batch is not None and vis_clear_batch is not None and vis_pred_batch is not None and vis_indices:\n",
    "            try:\n",
    "                # Pass the actual original indices used for visualization\n",
    "                montage = create_sample_montage(vis_blurry_batch, vis_pred_batch, vis_clear_batch, vis_indices)\n",
    "                if montage is not None:\n",
    "                    sample_path = os.path.join(samples_dir, f\"sample_montage_epoch_{epoch+1:03d}.png\")\n",
    "                    cv2.imwrite(sample_path, montage)\n",
    "                    # print(f\"Saved validation sample montage to {sample_path}\") # Optional print\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating or saving sample montage for epoch {epoch+1}: {e}\")\n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            print(f\"Skipping montage generation for epoch {epoch+1} (missing visualization data or indices).\")\n",
    "\n",
    "\n",
    "        # --- Checkpoint Saving ---\n",
    "\n",
    "        # Save best model based on validation loss\n",
    "        if val_loss < best_val_loss and val_loss != float('inf'):\n",
    "            best_val_loss = val_loss\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                }, best_model_path) # Use the predefined path\n",
    "                print(f\"*** New best model saved with Validation Loss {val_loss:.6f} at Epoch {epoch+1} ***\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving best model checkpoint: {e}\")\n",
    "\n",
    "        # Save periodic checkpoint (e.g., every 10 epochs or last epoch)\n",
    "        if (epoch + 1) % 10 == 0 or epoch == epochs - 1:\n",
    "            checkpoint_path = os.path.join(checkpoints_dir, f\"wavelet_unet_bn_epoch_{epoch+1:03d}.pth\")\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                }, checkpoint_path)\n",
    "                print(f\"Saved periodic checkpoint to {checkpoint_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving periodic checkpoint: {e}\")\n",
    "\n",
    "        epoch_duration = datetime.now() - epoch_start_time\n",
    "        print(f\"Epoch {epoch+1} completed in {str(epoch_duration).split('.')[0]}\")\n",
    "\n",
    "    # --- End of Training Loop ---\n",
    "\n",
    "    print(\"\\n--- Training Finished ---\")\n",
    "\n",
    "    # Save final model state (useful regardless of best validation loss)\n",
    "    final_model_path = os.path.join(output_dir, \"wavelet_unet_bn_final.pth\")\n",
    "    try:\n",
    "        torch.save({\n",
    "            'epoch': epochs, # Save final epoch number\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'best_val_loss': best_val_loss, # Record the best val loss achieved\n",
    "        }, final_model_path)\n",
    "        print(f\"Saved final model state to {final_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final model state: {e}\")\n",
    "\n",
    "    # Generate and save loss curves plot\n",
    "    try:\n",
    "        # Read the CSV file with training history\n",
    "        if os.path.exists(csv_path):\n",
    "            history_df = pd.read_csv(csv_path)\n",
    "\n",
    "            # Convert loss columns to numeric, coercing errors to NaN\n",
    "            history_df['Training Loss'] = pd.to_numeric(history_df['Training Loss'], errors='coerce')\n",
    "            history_df['Validation Loss'] = pd.to_numeric(history_df['Validation Loss'], errors='coerce')\n",
    "\n",
    "            # Drop rows where loss is NaN (e.g., if logging failed for an epoch)\n",
    "            history_df.dropna(subset=['Training Loss', 'Validation Loss'], inplace=True)\n",
    "\n",
    "            if not history_df.empty:\n",
    "                plt.figure(figsize=(12, 7)) # Wider figure\n",
    "                plt.plot(history_df['Epoch'], history_df['Training Loss'], label='Training Loss', marker='o', linestyle='-')\n",
    "                plt.plot(history_df['Epoch'], history_df['Validation Loss'], label='Validation Loss', marker='x', linestyle='--')\n",
    "\n",
    "                # Add titles and labels\n",
    "                plt.title('Training and Validation Loss Curves')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Loss (L1 + Wavelet L1)')\n",
    "                plt.legend()\n",
    "                plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "                plt.yscale('log') # Use log scale if losses vary greatly\n",
    "                plt.tight_layout() # Adjust layout\n",
    "\n",
    "                # Save the plot\n",
    "                plot_path = os.path.join(output_dir, \"loss_curves.png\")\n",
    "                plt.savefig(plot_path)\n",
    "                print(f\"Saved loss curves plot to {plot_path}\")\n",
    "                plt.close() # Close the plot to free memory\n",
    "            else:\n",
    "                print(\"No valid data found in CSV to plot loss curves.\")\n",
    "        else:\n",
    "            print(f\"Could not find CSV file {csv_path} to generate plot.\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"Plotting requires matplotlib and pandas. Please install them (`pip install matplotlib pandas`)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating loss curves plot: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    print(f\"Best validation loss achieved: {best_val_loss:.6f}\")\n",
    "    print(f\"Find best model at: {best_model_path}\")\n",
    "    print(f\"Find final model at: {final_model_path}\")\n",
    "    print(f\"Find training status log at: {csv_path}\")\n",
    "    print(f\"Find sample montages in: {samples_dir}\")\n",
    "    print(f\"Find checkpoints in: {checkpoints_dir}\")\n",
    "\n",
    "    return model # Return the trained model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configure directories (Use absolute paths or paths relative to script location)\n",
    "    # Example using absolute paths (replace with your actual paths)\n",
    "    base_notebook_dir = \"/notebooks\" # Or wherever your notebooks directory is mounted\n",
    "    clear_dir = os.path.join(base_notebook_dir, \"output_3_18/smokeV2/clear\")\n",
    "    blurry_dir = os.path.join(base_notebook_dir, \"output_3_18/smokeV2/blurry\")\n",
    "    output_dir = os.path.join(base_notebook_dir, \"output_3_18/smoke/output_V3_with_validation_FIXED\")\n",
    "\n",
    "    # Make sure the output directory exists\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating output directory {output_dir}: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Print configuration clearly\n",
    "    print(\"--- Configuration ---\")\n",
    "    print(f\"Clear image directory : {os.path.abspath(clear_dir)}\")\n",
    "    print(f\"Blurry image directory: {os.path.abspath(blurry_dir)}\")\n",
    "    print(f\"Output directory      : {os.path.abspath(output_dir)}\")\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    # Check if input directories exist\n",
    "    if not os.path.isdir(clear_dir):\n",
    "        print(f\"Error: Clear image directory not found at '{clear_dir}'\")\n",
    "        sys.exit(1)\n",
    "    if not os.path.isdir(blurry_dir):\n",
    "        print(f\"Error: Blurry image directory not found at '{blurry_dir}'\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    try:\n",
    "        # Start training with defined parameters\n",
    "        trained_model = train_model(\n",
    "            clear_dir=clear_dir,\n",
    "            blurry_dir=blurry_dir,\n",
    "            output_dir=output_dir,\n",
    "            epochs=50,                     # Total number of epochs\n",
    "            batch_size=8,                  # Batch size (adjust based on GPU memory)\n",
    "            lr=0.0005,                     # Initial learning rate\n",
    "            wavelet='db1',                 # Wavelet type for loss and input features\n",
    "            alpha=0.85,                    # Loss balance (0.85*Spatial + 0.15*Frequency)\n",
    "            weight_decay=1e-5,             # Weight decay for AdamW optimizer\n",
    "            train_samples_per_epoch=1000,  # Max training samples per epoch subset\n",
    "            val_samples_per_epoch=200,     # Max validation samples per epoch subset (increased for better stats)\n",
    "            train_val_split=0.8,           # 80% training, 20% validation split\n",
    "            random_seed=42,                # Seed for reproducibility\n",
    "            num_workers=4                  # Number of CPU workers for DataLoader (adjust based on system)\n",
    "        )\n",
    "\n",
    "        if trained_model:\n",
    "            print(\"\\n--- Training script completed successfully! ---\")\n",
    "        else:\n",
    "            print(\"\\n--- Training script finished with errors (model returned None). ---\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "         print(\"\\n--- Training interrupted by user (KeyboardInterrupt). ---\")\n",
    "         sys.exit(0) # Exit cleanly\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- An unexpected error occurred during script execution ---\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        print(\"--- Traceback ---\")\n",
    "        traceback.print_exc()\n",
    "        print(\"-----------------\")\n",
    "        sys.exit(1) # Exit with error code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f90a19-10d1-48aa-97c9-c5ab2c622718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
