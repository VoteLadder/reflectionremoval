{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723f58bc-c52f-49d5-a2c8-e7eca8ef8b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This program creates non-specular images from specular images by scanning adjacent frames for correct pixels. It then creates two\n",
    "#Directories for training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ded349-4b4d-4632-a1bb-0f77328f3081",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Parameter Tuning ---\n",
      "  1. HSV Val Thresh (hsv_v): 130\n",
      "  2. HSV Sat Max    (hsv_s): 75\n",
      "  3. Wavelet Thresh (wavelet): 0.05\n",
      "  4. Min Contour Area (area): 3\n",
      "  5. Dilation Kernel (dilate): 13\n",
      "\n",
      "Gen samples in 'dataset/tuning_samples'...\n",
      "Review samples in 'dataset/tuning_samples'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Acceptable? (y/n/q):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params accepted.\n",
      "\n",
      "--- Using Tuned Parameters: ---\n",
      "  SPECULAR_THRESHOLD_HSV_V: 130\n",
      "  SPECULAR_THRESHOLD_HSV_S: 75\n",
      "  SPECULAR_THRESHOLD_WAVELET: 0.05\n",
      "  MIN_CONTOUR_AREA: 3\n",
      "  DILATION_KERNEL_SIZE: 13\n",
      "---------------------------------\n",
      "Created directory: dataset/ground_truth_frames_temporal_v2\n",
      "Created directory: dataset/detection_samples_temporal_v2\n",
      "Video frames: 1548\n",
      "Step 1: Reading all frames and detecting specular masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading & Masking Frames: 100%|██████████| 1548/1548 [08:44<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1548 frames and their masks.\n",
      "\n",
      "Step 2: Performing temporal inpainting with validation for ground truth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temporal Inpainting & Saving: 100%|██████████| 1548/1548 [30:42<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete. 1548 paired frames saved.\n",
      "Originals: dataset/original_frames\n",
      "Ground Truth: dataset/ground_truth_frames_temporal_v2\n",
      "Detection Samples: dataset/detection_samples_temporal_v2\n",
      "Tuning Samples were in: dataset/tuning_samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pywt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "CONFIG = {\n",
    "    \"VIDEO_PATH\": \"video.mp4\",\n",
    "    \"OUTPUT_ORIGINAL_DIR\": \"dataset/original_frames\",\n",
    "    \"OUTPUT_GROUND_TRUTH_DIR\": \"dataset/ground_truth_frames_temporal_v2\", # New output dir\n",
    "    \"TUNING_SAMPLE_DIR\": \"dataset/tuning_samples\",\n",
    "    \"DETECTION_SAMPLE_DIR\": \"dataset/detection_samples_temporal_v2\", # New sample dir\n",
    "    \"TARGET_IMG_SIZE\": (512, 512),\n",
    "    # --- Detection Parameters ---\n",
    "    \"SPECULAR_THRESHOLD_HSV_V\": 130,\n",
    "    \"SPECULAR_THRESHOLD_HSV_S\": 75,\n",
    "    \"SPECULAR_THRESHOLD_WAVELET\": 0.05,\n",
    "    \"MIN_CONTOUR_AREA\": 3,\n",
    "    \"DILATION_KERNEL_SIZE\": 13,\n",
    "    # --- Other Parameters ---\n",
    "    \"WAVELET\": \"haar\",\n",
    "    \"WAVELET_LEVEL\": 2,\n",
    "    \"FRAME_SKIP\": 0,\n",
    "    \"SAMPLE_EVERY_N_FRAMES\": 20,\n",
    "    \"NUM_INITIAL_SAMPLES_FOR_TUNING\": 5,\n",
    "    # --- Temporal Inpainting Parameters ---\n",
    "    \"TEMPORAL_SEARCH_WINDOW_PAST\": 10, # Keep these moderate\n",
    "    \"TEMPORAL_SEARCH_WINDOW_FUTURE\": 10,\n",
    "    \"MIN_BRIGHTNESS_FOR_TEMPORAL_SOURCE\": 40, # Min brightness for a replacement pixel\n",
    "    \"MIN_SATURATION_FOR_TEMPORAL_SOURCE\": 30, # Min saturation for a replacement pixel\n",
    "    \"HUE_RED_LOWER1\": 0, \"HUE_RED_UPPER1\": 20,   # Broader red hue\n",
    "    \"HUE_RED_LOWER2\": 160, \"HUE_RED_UPPER2\": 179, # Broader red hue\n",
    "    \"FALLBACK_INPAINT_RADIUS\": 3, # Radius for cv2.inpaint if no temporal source found\n",
    "}\n",
    "\n",
    "def create_dir_if_not_exists(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path); print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "def clear_dir(dir_path):\n",
    "    if os.path.exists(dir_path): shutil.rmtree(dir_path)\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "def dilate_mask(mask, dilation_kernel_size):\n",
    "    if dilation_kernel_size <= 1: return mask.astype(bool)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilation_kernel_size, dilation_kernel_size))\n",
    "    dilated_mask = cv2.dilate(mask.astype(np.uint8), kernel, iterations=1)\n",
    "    return dilated_mask.astype(bool)\n",
    "\n",
    "def detect_specular_regions(frame, current_config):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    v_channel, s_channel = hsv[:, :, 2], hsv[:, :, 1]\n",
    "    hsv_mask_ = (v_channel > current_config[\"SPECULAR_THRESHOLD_HSV_V\"]) & \\\n",
    "               (s_channel < current_config[\"SPECULAR_THRESHOLD_HSV_S\"])\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    wavelet_mask_ = np.zeros_like(gray, dtype=bool)\n",
    "    try:\n",
    "        coeffs = pywt.wavedec2(gray, current_config[\"WAVELET\"], level=current_config[\"WAVELET_LEVEL\"])\n",
    "        details = []\n",
    "        for c_level in coeffs[1:]:\n",
    "            for d_idx in range(len(c_level)):\n",
    "                 details.append(cv2.resize(np.abs(c_level[d_idx]), (gray.shape[1], gray.shape[0])))\n",
    "        if details:\n",
    "            max_detail = np.max(np.stack(details), axis=0)\n",
    "            min_v, max_v = np.min(max_detail), np.max(max_detail)\n",
    "            norm_details = (max_detail - min_v) / (max_v - min_v + 1e-6) if max_v > min_v else np.zeros_like(max_detail)\n",
    "            wavelet_mask_ = norm_details > current_config[\"SPECULAR_THRESHOLD_WAVELET\"]\n",
    "    except Exception as e: print(f\"  Warn: Wavelet err: {e}.\")\n",
    "\n",
    "    combined = np.logical_or(hsv_mask_, wavelet_mask_)\n",
    "    k_morph = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    morphed = cv2.morphologyEx(cv2.morphologyEx(combined.astype(np.uint8), cv2.MORPH_CLOSE, k_morph), cv2.MORPH_OPEN, k_morph)\n",
    "    \n",
    "    final_m = np.zeros_like(morphed, dtype=np.uint8)\n",
    "    contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > current_config[\"MIN_CONTOUR_AREA\"]:\n",
    "            cv2.drawContours(final_m, [cnt], -1, 1, thickness=cv2.FILLED)\n",
    "    \n",
    "    return dilate_mask(final_m, current_config[\"DILATION_KERNEL_SIZE\"])\n",
    "\n",
    "def get_user_tuned_parameters(initial_config, video_path):\n",
    "    tuned_cfg = initial_config.copy()\n",
    "    if \"DILATION_KERNEL_SIZE\" not in tuned_cfg:\n",
    "        tuned_cfg[\"DILATION_KERNEL_SIZE\"] = initial_config.get(\"DILATION_KERNEL_SIZE\", 13) # Use the one in CONFIG\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened(): print(f\"Error: No video for tuning: {video_path}\"); return None\n",
    "    \n",
    "    sample_frames = []\n",
    "    for _ in range(tuned_cfg[\"NUM_INITIAL_SAMPLES_FOR_TUNING\"]):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        sample_frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    if not sample_frames: print(\"No frames for tuning.\"); return None\n",
    "    create_dir_if_not_exists(tuned_cfg[\"TUNING_SAMPLE_DIR\"])\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n--- Parameter Tuning ---\")\n",
    "        print(f\"  1. HSV Val Thresh (hsv_v): {tuned_cfg['SPECULAR_THRESHOLD_HSV_V']}\")\n",
    "        print(f\"  2. HSV Sat Max    (hsv_s): {tuned_cfg['SPECULAR_THRESHOLD_HSV_S']}\")\n",
    "        print(f\"  3. Wavelet Thresh (wavelet): {tuned_cfg['SPECULAR_THRESHOLD_WAVELET']:.2f}\")\n",
    "        print(f\"  4. Min Contour Area (area): {tuned_cfg['MIN_CONTOUR_AREA']}\")\n",
    "        print(f\"  5. Dilation Kernel (dilate): {tuned_cfg['DILATION_KERNEL_SIZE']}\")\n",
    "        \n",
    "        clear_dir(tuned_cfg[\"TUNING_SAMPLE_DIR\"])\n",
    "        print(f\"\\nGen samples in '{tuned_cfg['TUNING_SAMPLE_DIR']}'...\")\n",
    "        for i, frame in enumerate(sample_frames):\n",
    "            if frame is None: continue # Skip if a frame is None\n",
    "            orig_s = cv2.resize(frame, tuned_cfg[\"TARGET_IMG_SIZE\"])\n",
    "            mask_os = detect_specular_regions(frame, tuned_cfg)\n",
    "            mask_rs = cv2.resize(mask_os.astype(np.uint8)*255, tuned_cfg[\"TARGET_IMG_SIZE\"], interpolation=cv2.INTER_NEAREST)\n",
    "            mask_vis = cv2.cvtColor(mask_rs, cv2.COLOR_GRAY2BGR)\n",
    "            high_s = orig_s.copy()\n",
    "            high_s[mask_rs > 0] = [0, 0, 255] \n",
    "            cv2.imwrite(os.path.join(tuned_cfg[\"TUNING_SAMPLE_DIR\"], f\"tune_s_{i}.png\"), np.concatenate((orig_s, high_s, mask_vis), axis=1))\n",
    "        \n",
    "        print(f\"Review samples in '{tuned_cfg['TUNING_SAMPLE_DIR']}'.\")\n",
    "        choice = input(\"Acceptable? (y/n/q): \").lower()\n",
    "        if choice == 'y': print(\"Params accepted.\"); return tuned_cfg\n",
    "        if choice == 'q': print(\"Tuning quit.\"); return None\n",
    "        if choice == 'n':\n",
    "            print(\"\\nAdjust (blank to keep current):\")\n",
    "            try:\n",
    "                def _get_val(prompt, current, type_conv):\n",
    "                    val = input(prompt(current))\n",
    "                    return type_conv(val) if val else current\n",
    "                tuned_cfg[\"SPECULAR_THRESHOLD_HSV_V\"] = _get_val(lambda c: f\"  HSV Val (cur {c}): \", tuned_cfg[\"SPECULAR_THRESHOLD_HSV_V\"], int)\n",
    "                tuned_cfg[\"SPECULAR_THRESHOLD_HSV_S\"] = _get_val(lambda c: f\"  HSV Sat (cur {c}): \", tuned_cfg[\"SPECULAR_THRESHOLD_HSV_S\"], int)\n",
    "                tuned_cfg[\"SPECULAR_THRESHOLD_WAVELET\"] = _get_val(lambda c: f\"  Wavelet (cur {c:.2f}): \", tuned_cfg[\"SPECULAR_THRESHOLD_WAVELET\"], float)\n",
    "                tuned_cfg[\"MIN_CONTOUR_AREA\"] = _get_val(lambda c: f\"  Min Area (cur {c}): \", tuned_cfg[\"MIN_CONTOUR_AREA\"], int)\n",
    "                tuned_cfg[\"DILATION_KERNEL_SIZE\"] = _get_val(lambda c: f\"  Dilation (cur {c}): \", tuned_cfg[\"DILATION_KERNEL_SIZE\"], int)\n",
    "            except ValueError: print(\"Invalid input type.\")\n",
    "        else: print(\"Invalid choice.\")\n",
    "\n",
    "def is_pixel_valid_temporal_source(pixel_bgr, config):\n",
    "    \"\"\"Checks if a BGR pixel is a valid 'tissue-like' source for temporal inpainting.\"\"\"\n",
    "    # Convert BGR to HSV for checking\n",
    "    # Note: Converting single pixels repeatedly can be slow.\n",
    "    # If performance is an issue, convert the whole neighbor_frame to HSV once.\n",
    "    hsv_pixel_arr = cv2.cvtColor(np.uint8([[pixel_bgr]]), cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = hsv_pixel_arr[0][0]\n",
    "\n",
    "    if v < config[\"MIN_BRIGHTNESS_FOR_TEMPORAL_SOURCE\"]: return False\n",
    "    if s < config[\"MIN_SATURATION_FOR_TEMPORAL_SOURCE\"]: return False\n",
    "\n",
    "    is_red = (config[\"HUE_RED_LOWER1\"] <= h <= config[\"HUE_RED_UPPER1\"]) or \\\n",
    "             (config[\"HUE_RED_LOWER2\"] <= h <= config[\"HUE_RED_UPPER2\"])\n",
    "    return is_red\n",
    "\n",
    "\n",
    "def temporally_inpaint_frame_with_validation(current_frame_idx, all_frames_list, all_masks_list, config_obj):\n",
    "    current_frame = all_frames_list[current_frame_idx]\n",
    "    current_specular_mask = all_masks_list[current_frame_idx]\n",
    "    \n",
    "    gt_frame = current_frame.copy()\n",
    "    num_loaded_frames = len(all_frames_list)\n",
    "\n",
    "    if not np.any(current_specular_mask):\n",
    "        return gt_frame # No speculars to inpaint\n",
    "\n",
    "    specular_coords_y, specular_coords_x = np.where(current_specular_mask)\n",
    "\n",
    "    # For fallback inpainting, create a mask of pixels that couldn't be temporally inpainted\n",
    "    unresolved_specular_mask_for_fallback = np.zeros_like(current_specular_mask, dtype=np.uint8)\n",
    "\n",
    "    for r, c in zip(specular_coords_y, specular_coords_x):\n",
    "        pixel_replaced = False\n",
    "        \n",
    "        # Search backward then forward, prioritizing closer frames\n",
    "        search_order = []\n",
    "        # Past frames\n",
    "        for i in range(1, config_obj[\"TEMPORAL_SEARCH_WINDOW_PAST\"] + 1):\n",
    "            idx = current_frame_idx - i\n",
    "            if idx >= 0: search_order.append(idx)\n",
    "            else: break\n",
    "        # Future frames\n",
    "        for i in range(1, config_obj[\"TEMPORAL_SEARCH_WINDOW_FUTURE\"] + 1):\n",
    "            idx = current_frame_idx + i\n",
    "            if idx < num_loaded_frames: search_order.append(idx)\n",
    "            else: break\n",
    "            \n",
    "        for neighbor_idx in search_order:\n",
    "            neighbor_frame = all_frames_list[neighbor_idx]\n",
    "            # Check if the pixel in neighbor_frame is NOT specular AND is a valid color\n",
    "            if not all_masks_list[neighbor_idx][r, c]:\n",
    "                candidate_pixel_bgr = neighbor_frame[r, c]\n",
    "                if is_pixel_valid_temporal_source(candidate_pixel_bgr, config_obj):\n",
    "                    gt_frame[r, c] = candidate_pixel_bgr\n",
    "                    pixel_replaced = True\n",
    "                    break # Found a good replacement\n",
    "            if pixel_replaced: break\n",
    "        \n",
    "        if not pixel_replaced:\n",
    "            # Mark this pixel for fallback spatial inpainting\n",
    "            unresolved_specular_mask_for_fallback[r, c] = 255 # OpenCV inpaint needs 255 for mask\n",
    "\n",
    "    # Fallback for unresolved pixels: apply cv2.inpaint\n",
    "    if np.any(unresolved_specular_mask_for_fallback):\n",
    "        # Important: inpaint on the 'gt_frame' which might have some pixels already filled temporally\n",
    "        # This ensures we don't overwrite good temporal fills with spatial ones.\n",
    "        # However, cv2.inpaint works best if it has good boundaries from the original frame.\n",
    "        # So, we inpaint on the original frame, but only apply the result to unresolved pixels.\n",
    "        \n",
    "        # Create a temporary frame for inpainting that starts as the original\n",
    "        temp_inpaint_source = current_frame.copy()\n",
    "        # But fill in already resolved pixels from gt_frame, so inpaint uses those as boundary if close\n",
    "        # This gets complex. Simpler: Inpaint on original, apply only to unresolved.\n",
    "        \n",
    "        inpainted_fallback_region = cv2.inpaint(current_frame, # Source is original frame\n",
    "                                                unresolved_specular_mask_for_fallback,\n",
    "                                                config_obj[\"FALLBACK_INPAINT_RADIUS\"],\n",
    "                                                cv2.INPAINT_TELEA) # Or INPAINT_NS\n",
    "        \n",
    "        # Apply the fallback only to the pixels that were marked as unresolved\n",
    "        gt_frame[unresolved_specular_mask_for_fallback == 255] = \\\n",
    "            inpainted_fallback_region[unresolved_specular_mask_for_fallback == 255]\n",
    "            \n",
    "    return gt_frame\n",
    "\n",
    "\n",
    "def main():\n",
    "    effective_config = get_user_tuned_parameters(CONFIG, CONFIG[\"VIDEO_PATH\"])\n",
    "    if effective_config is None: print(\"Exiting.\"); return\n",
    "    \n",
    "    print(\"\\n--- Using Tuned Parameters: ---\")\n",
    "    for k in [\"SPECULAR_THRESHOLD_HSV_V\", \"SPECULAR_THRESHOLD_HSV_S\", \"SPECULAR_THRESHOLD_WAVELET\", \"MIN_CONTOUR_AREA\", \"DILATION_KERNEL_SIZE\"]:\n",
    "        if k in effective_config: print(f\"  {k}: {effective_config[k]}\")\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "    for dir_key in [\"OUTPUT_ORIGINAL_DIR\", \"OUTPUT_GROUND_TRUTH_DIR\", \"DETECTION_SAMPLE_DIR\"]:\n",
    "        create_dir_if_not_exists(effective_config[dir_key])\n",
    "\n",
    "    cap = cv2.VideoCapture(effective_config[\"VIDEO_PATH\"])\n",
    "    if not cap.isOpened(): print(f\"Error: No video: {effective_config['VIDEO_PATH']}\"); return\n",
    "    total_frames_in_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Video frames: {total_frames_in_video}\")\n",
    "\n",
    "    print(\"Step 1: Reading all frames and detecting specular masks...\")\n",
    "    all_frames_list = []\n",
    "    all_masks_list = []\n",
    "    \n",
    "    for i in tqdm(range(total_frames_in_video), desc=\"Reading & Masking Frames\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: print(f\"Warn: No frame {i}. Stop.\"); break\n",
    "        all_frames_list.append(frame)\n",
    "        # Detect mask using original frame size\n",
    "        mask = detect_specular_regions(frame, effective_config)\n",
    "        all_masks_list.append(mask)\n",
    "    cap.release()\n",
    "    \n",
    "    if not all_frames_list: print(\"No frames read.\"); return\n",
    "    num_loaded_frames = len(all_frames_list)\n",
    "    print(f\"Loaded {num_loaded_frames} frames and their masks.\")\n",
    "\n",
    "    print(\"\\nStep 2: Performing temporal inpainting with validation for ground truth...\")\n",
    "    saved_frame_idx = 0\n",
    "    for current_frame_idx in tqdm(range(num_loaded_frames), desc=\"Temporal Inpainting & Saving\"):\n",
    "        if effective_config[\"FRAME_SKIP\"] > 0 and current_frame_idx % (effective_config[\"FRAME_SKIP\"] + 1) != 0:\n",
    "            continue\n",
    "\n",
    "        original_frame = all_frames_list[current_frame_idx]\n",
    "        \n",
    "        # Perform temporal inpainting with validation\n",
    "        gt_frame = temporally_inpaint_frame_with_validation(\n",
    "            current_frame_idx, all_frames_list, all_masks_list, effective_config\n",
    "        )\n",
    "\n",
    "        orig_resized = cv2.resize(original_frame, effective_config[\"TARGET_IMG_SIZE\"])\n",
    "        gt_resized = cv2.resize(gt_frame, effective_config[\"TARGET_IMG_SIZE\"])\n",
    "        \n",
    "        fname = f\"frame_{saved_frame_idx:06d}.png\"\n",
    "        cv2.imwrite(os.path.join(effective_config[\"OUTPUT_ORIGINAL_DIR\"], fname), orig_resized)\n",
    "        cv2.imwrite(os.path.join(effective_config[\"OUTPUT_GROUND_TRUTH_DIR\"], fname), gt_resized)\n",
    "\n",
    "        if saved_frame_idx > 0 and saved_frame_idx % effective_config[\"SAMPLE_EVERY_N_FRAMES\"] == 0:\n",
    "            # For sample, use the mask that was generated for this frame\n",
    "            specular_mask_for_sample = all_masks_list[current_frame_idx]\n",
    "            mask_resized = cv2.resize(specular_mask_for_sample.astype(np.uint8)*255, \n",
    "                                      effective_config[\"TARGET_IMG_SIZE\"], \n",
    "                                      interpolation=cv2.INTER_NEAREST)\n",
    "            mask_vis = cv2.cvtColor(mask_resized, cv2.COLOR_GRAY2BGR)\n",
    "            orig_sample_highlighted = orig_resized.copy()\n",
    "            orig_sample_highlighted[mask_resized > 0] = [0, 0, 255]\n",
    "            sample_display = np.concatenate((orig_resized, orig_sample_highlighted, gt_resized, mask_vis), axis=1)\n",
    "            cv2.imwrite(os.path.join(effective_config[\"DETECTION_SAMPLE_DIR\"], f\"gt_gen_samp_{saved_frame_idx:06d}.png\"), sample_display)\n",
    "        \n",
    "        saved_frame_idx += 1\n",
    "\n",
    "    print(f\"\\nComplete. {saved_frame_idx} paired frames saved.\")\n",
    "    print(f\"Originals: {effective_config['OUTPUT_ORIGINAL_DIR']}\")\n",
    "    print(f\"Ground Truth: {effective_config['OUTPUT_GROUND_TRUTH_DIR']}\")\n",
    "    print(f\"Detection Samples: {effective_config['DETECTION_SAMPLE_DIR']}\")\n",
    "    print(f\"Tuning Samples were in: {effective_config['TUNING_SAMPLE_DIR']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda4935-03d4-40c7-8b09-a45f762ef4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
